{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Standard Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\debapriya.mukherjee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "C:\\Users\\debapriya.mukherjee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import glob\n",
    "import docx2txt\n",
    "from io import BytesIO\n",
    "from nltk import word_tokenize\n",
    "from sacremoses import MosesDetokenizer\n",
    "detokenizer = MosesDetokenizer()\n",
    "import re\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from flask import Flask, abort, request, jsonify\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#Creating database for Automotive\n",
    "automtv = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/Automotive.xls')\n",
    "automtv.sheet_names\n",
    "df01= automtv.parse('Sheet1')\n",
    "df2= automtv.parse('Sheet2')\n",
    "\n",
    "df01.loc[df01['Capability Area'].isnull() & df01['Capability'].isnull() & df01['Process'].isnull() & df01['Sub Process'].isnull() & df01['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df01.loc[df01['Capability'].isnull() & df01['Process'].isnull() & df01['Sub Process'].isnull() & df01['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df01.loc[df01['Process'].isnull() & df01['Sub Process'].isnull() & df01['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df01.loc[df01['Sub Process'].isnull() & df01['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df01.loc[df01['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df01['Platform'] = df01['Platform'].ffill().astype(str)\n",
    "df01['Capability Area'] = df01['Capability Area'].ffill().astype(str)\n",
    "df01['Capability'] = df01['Capability'].ffill().astype(str)\n",
    "df01['Process'] = df01['Process'].ffill().astype(str)\n",
    "df01['Sub Process'] = df01['Sub Process'].ffill().astype(str)\n",
    "df01['Activity'] = df01['Activity'].ffill().astype(str)\n",
    "\n",
    "df1 = df01.replace(\"Y\", np.nan)\n",
    "\n",
    "Automotive = pd.merge(df1, df2, on = 'Asset ID', how= 'inner')\n",
    "Automotive[\"Industry\"]=\"\"\n",
    "Automotive[\"HierarId\"]=\"\"\n",
    "Automotive[\"Content\"]=\"\"\n",
    "#Automotive\n",
    "\n",
    "\n",
    "#Creating database for Chemicals\n",
    "chem = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/Chemicals.xls')\n",
    "chem.sheet_names\n",
    "df03= chem.parse('Sheet1')\n",
    "df4= chem.parse('Sheet2')\n",
    "\n",
    "df03.loc[df03['Capability Area'].isnull() & df03['Capability'].isnull() & df03['Process'].isnull() & df03['Sub Process'].isnull() & df03['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df03.loc[df03['Capability'].isnull() & df03['Process'].isnull() & df03['Sub Process'].isnull() & df03['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df03.loc[df03['Process'].isnull() & df03['Sub Process'].isnull() & df03['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df03.loc[df03['Sub Process'].isnull() & df03['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df03.loc[df03['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df03['Platform'] = df03['Platform'].ffill().astype(str)\n",
    "df03['Capability Area'] = df03['Capability Area'].ffill().astype(str)\n",
    "df03['Capability'] = df03['Capability'].ffill().astype(str)\n",
    "df03['Process'] = df03['Process'].ffill().astype(str)\n",
    "df03['Sub Process'] = df03['Sub Process'].ffill().astype(str)\n",
    "df03['Activity'] = df03['Activity'].ffill().astype(str)\n",
    "\n",
    "df3 = df03.replace(\"Y\", np.nan)\n",
    "\n",
    "Chemicals = pd.merge(df3, df4, on = 'Asset ID', how= 'inner')\n",
    "Chemicals[\"Industry\"]=\"\"\n",
    "Chemicals[\"HierarId\"]=\"\"\n",
    "Chemicals[\"Content\"]=\"\"\n",
    "#Chemicals\n",
    "\n",
    "\n",
    "\n",
    "#Creating database for Aerospace Defense\n",
    "aerodef = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/AerospaceDefense/Aerospace_Defense.xls')\n",
    "aerodef.sheet_names\n",
    "df05= aerodef.parse('Sheet1')\n",
    "df6= aerodef.parse('Sheet2')\n",
    "\n",
    "df05.loc[df05['Capability Area'].isnull() & df05['Capability'].isnull() & df05['Process'].isnull() & df05['Sub Process'].isnull() & df05['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df05.loc[df05['Capability'].isnull() & df05['Process'].isnull() & df05['Sub Process'].isnull() & df05['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df05.loc[df05['Process'].isnull() & df05['Sub Process'].isnull() & df05['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df05.loc[df05['Sub Process'].isnull() & df05['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df05.loc[df05['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df05['Platform'] = df05['Platform'].ffill().astype(str)\n",
    "df05['Capability Area'] = df05['Capability Area'].ffill().astype(str)\n",
    "df05['Capability'] = df05['Capability'].ffill().astype(str)\n",
    "df05['Process'] = df05['Process'].ffill().astype(str)\n",
    "df05['Sub Process'] = df05['Sub Process'].ffill().astype(str)\n",
    "df05['Activity'] = df05['Activity'].ffill().astype(str)\n",
    "\n",
    "df5 = df05.replace(\"Y\", np.nan)\n",
    "\n",
    "AerospaceD = pd.merge(df5, df6, on = 'Asset ID', how= 'inner')\n",
    "AerospaceD[\"Industry\"]=\"\"\n",
    "AerospaceD[\"HierarId\"]=\"\"\n",
    "AerospaceD[\"Content\"]=\"\"\n",
    "\n",
    "\n",
    "#Creating database for AgriBusinessGrain\n",
    "agri = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/AgriBusinessGrain/AgriBusiness_Grain.xls')\n",
    "agri.sheet_names\n",
    "df07= agri.parse('Sheet1')\n",
    "df8= agri.parse('Sheet2')\n",
    "\n",
    "df07.loc[df07['Capability Area'].isnull() & df07['Capability'].isnull() & df07['Process'].isnull() & df07['Sub Process'].isnull() & df07['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df07.loc[df07['Capability'].isnull() & df07['Process'].isnull() & df07['Sub Process'].isnull() & df07['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df07.loc[df07['Process'].isnull() & df07['Sub Process'].isnull() & df07['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df07.loc[df07['Sub Process'].isnull() & df07['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df07.loc[df07['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df07['Platform'] = df07['Platform'].ffill().astype(str)\n",
    "df07['Capability Area'] = df07['Capability Area'].ffill().astype(str)\n",
    "df07['Capability'] = df07['Capability'].ffill().astype(str)\n",
    "df07['Process'] = df07['Process'].ffill().astype(str)\n",
    "df07['Sub Process'] = df07['Sub Process'].ffill().astype(str)\n",
    "df07['Activity'] = df07['Activity'].ffill().astype(str)\n",
    "\n",
    "df7 = df07.replace(\"Y\", np.nan)\n",
    "\n",
    "AgriGrain = pd.merge(df7, df8, on = 'Asset ID', how= 'inner')\n",
    "AgriGrain[\"Industry\"]=\"\"\n",
    "AgriGrain[\"HierarId\"]=\"\"\n",
    "AgriGrain[\"Content\"]=\"\"\n",
    "\n",
    "\n",
    "#Creating database for CGSNonAlcoholicBevg\n",
    "nonalcobvg = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/CGS_NonAlcoholic_Bevg/CGS_NonAlcoholic_Bevg.xls')\n",
    "nonalcobvg.sheet_names\n",
    "df09= nonalcobvg.parse('Sheet1')\n",
    "df10= nonalcobvg.parse('Sheet2')\n",
    "\n",
    "df09.loc[df09['Capability Area'].isnull() & df09['Capability'].isnull() & df09['Process'].isnull() & df09['Sub Process'].isnull() & df09['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df09.loc[df09['Capability'].isnull() & df09['Process'].isnull() & df09['Sub Process'].isnull() & df09['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df09.loc[df09['Process'].isnull() & df09['Sub Process'].isnull() & df09['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df09.loc[df09['Sub Process'].isnull() & df09['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df09.loc[df09['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df09['Platform'] = df09['Platform'].ffill().astype(str)\n",
    "df09['Capability Area'] = df09['Capability Area'].ffill().astype(str)\n",
    "df09['Capability'] = df09['Capability'].ffill().astype(str)\n",
    "df09['Process'] = df09['Process'].ffill().astype(str)\n",
    "df09['Sub Process'] = df09['Sub Process'].ffill().astype(str)\n",
    "df09['Activity'] = df09['Activity'].ffill().astype(str)\n",
    "\n",
    "df9 = df09.replace(\"Y\", np.nan)\n",
    "\n",
    "NonAlcoBvg = pd.merge(df9, df10, on = 'Asset ID', how= 'inner')\n",
    "NonAlcoBvg[\"Industry\"]=\"\"\n",
    "NonAlcoBvg[\"HierarId\"]=\"\"\n",
    "NonAlcoBvg[\"Content\"]=\"\"\n",
    "#NonAlcoBvg.head()\n",
    "\n",
    "\n",
    "#Creating database for CGS_Tobacco\n",
    "cgstobacco = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/CGS_Tobacco/CGS_Tobacco.xls')\n",
    "cgstobacco.sheet_names\n",
    "df011= cgstobacco.parse('Sheet1')\n",
    "df12= cgstobacco.parse('Sheet2')\n",
    "\n",
    "df011.loc[df011['Capability Area'].isnull() & df011['Capability'].isnull() & df011['Process'].isnull() & df011['Sub Process'].isnull() & df011['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df011.loc[df011['Capability'].isnull() & df011['Process'].isnull() & df011['Sub Process'].isnull() & df011['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df011.loc[df011['Process'].isnull() & df011['Sub Process'].isnull() & df011['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df011.loc[df011['Sub Process'].isnull() & df011['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df011.loc[df011['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df011['Platform'] = df011['Platform'].ffill().astype(str)\n",
    "df011['Capability Area'] = df011['Capability Area'].ffill().astype(str)\n",
    "df011['Capability'] = df011['Capability'].ffill().astype(str)\n",
    "df011['Process'] = df011['Process'].ffill().astype(str)\n",
    "df011['Sub Process'] = df011['Sub Process'].ffill().astype(str)\n",
    "df011['Activity'] = df011['Activity'].ffill().astype(str)\n",
    "\n",
    "df11 = df011.replace(\"Y\", np.nan)\n",
    "\n",
    "Tobacco = pd.merge(df11, df12, on = 'Asset ID', how= 'inner')\n",
    "Tobacco[\"Industry\"]=\"\"\n",
    "Tobacco[\"HierarId\"]=\"\"\n",
    "Tobacco[\"Content\"]=\"\"\n",
    "\n",
    "\n",
    "#Creating database for ConstructionEPC\n",
    "constepc = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/ConstructionEPC/ConstructionEPC.xls')\n",
    "constepc.sheet_names\n",
    "df013= constepc.parse('Sheet1')\n",
    "df14= constepc.parse('Sheet2')\n",
    "\n",
    "df013.loc[df013['Capability Area'].isnull() & df013['Capability'].isnull() & df013['Process'].isnull() & df013['Sub Process'].isnull() & df013['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df013.loc[df013['Capability'].isnull() & df013['Process'].isnull() & df013['Sub Process'].isnull() & df013['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df013.loc[df013['Process'].isnull() & df013['Sub Process'].isnull() & df013['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df013.loc[df013['Sub Process'].isnull() & df013['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df013.loc[df013['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df013['Platform'] = df013['Platform'].ffill().astype(str)\n",
    "df013['Capability Area'] = df013['Capability Area'].ffill().astype(str)\n",
    "df013['Capability'] = df013['Capability'].ffill().astype(str)\n",
    "df013['Process'] = df013['Process'].ffill().astype(str)\n",
    "df013['Sub Process'] = df013['Sub Process'].ffill().astype(str)\n",
    "df013['Activity'] = df013['Activity'].ffill().astype(str)\n",
    "\n",
    "df13 = df013.replace(\"Y\", np.nan)\n",
    "\n",
    "ConstructionEPC = pd.merge(df13, df14, on = 'Asset ID', how= 'inner')\n",
    "ConstructionEPC[\"Industry\"]=\"\"\n",
    "ConstructionEPC[\"HierarId\"]=\"\"\n",
    "ConstructionEPC[\"Content\"]=\"\"\n",
    "\n",
    "#ConstructionEPC.head()\n",
    "\n",
    "#Creating database for Consumer_Technology\n",
    "contech = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/Consumer_Technology/Consumer_Technology.xls')\n",
    "\n",
    "contech.sheet_names\n",
    "df015= contech.parse('Sheet1')\n",
    "df16= contech.parse('Sheet2')\n",
    "\n",
    "df015.loc[df015['Capability Area'].isnull() & df015['Capability'].isnull() & df015['Process'].isnull() & df015['Sub Process'].isnull() & df015['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df015.loc[df015['Capability'].isnull() & df015['Process'].isnull() & df015['Sub Process'].isnull() & df015['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df015.loc[df015['Process'].isnull() & df015['Sub Process'].isnull() & df015['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df015.loc[df015['Sub Process'].isnull() & df015['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df015.loc[df015['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df015['Platform'] = df015['Platform'].ffill().astype(str)\n",
    "df015['Capability Area'] = df015['Capability Area'].ffill().astype(str)\n",
    "df015['Capability'] = df015['Capability'].ffill().astype(str)\n",
    "df015['Process'] = df015['Process'].ffill().astype(str)\n",
    "df015['Sub Process'] = df015['Sub Process'].ffill().astype(str)\n",
    "df015['Activity'] = df015['Activity'].ffill().astype(str)\n",
    "\n",
    "df15 = df015.replace(\"Y\", np.nan)\n",
    "\n",
    "ConsumerTech = pd.merge(df15, df16, on = 'Asset ID', how= 'inner')\n",
    "ConsumerTech[\"Industry\"]=\"\"\n",
    "ConsumerTech[\"HierarId\"]=\"\"\n",
    "ConsumerTech[\"Content\"]=\"\"\n",
    "\n",
    "#ConsumerTech.head()\n",
    "\n",
    "\n",
    "#Creating database for Defense\n",
    "defns = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/Defense/Defense.xls')\n",
    "defns.sheet_names\n",
    "df017= contech.parse('Sheet1')\n",
    "df18= contech.parse('Sheet2')\n",
    "\n",
    "df017.loc[df017['Capability Area'].isnull() & df017['Capability'].isnull() & df017['Process'].isnull() & df017['Sub Process'].isnull() & df017['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df017.loc[df017['Capability'].isnull() & df017['Process'].isnull() & df017['Sub Process'].isnull() & df017['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df017.loc[df017['Process'].isnull() & df017['Sub Process'].isnull() & df017['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df017.loc[df017['Sub Process'].isnull() & df017['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df017.loc[df017['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df017['Platform'] = df017['Platform'].ffill().astype(str)\n",
    "df017['Capability Area'] = df017['Capability Area'].ffill().astype(str)\n",
    "df017['Capability'] = df017['Capability'].ffill().astype(str)\n",
    "df017['Process'] = df017['Process'].ffill().astype(str)\n",
    "df017['Sub Process'] = df017['Sub Process'].ffill().astype(str)\n",
    "df017['Activity'] = df017['Activity'].ffill().astype(str)\n",
    "\n",
    "df17 = df017.replace(\"Y\", np.nan)\n",
    "\n",
    "Defense = pd.merge(df17, df18, on = 'Asset ID', how= 'inner')\n",
    "Defense[\"Industry\"]=\"\"\n",
    "Defense[\"HierarId\"]=\"\"\n",
    "Defense[\"Content\"]=\"\"\n",
    "\n",
    "#Defense.head()\n",
    "\n",
    "#Creating database for EnergyDownstream\n",
    "engdwn = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/Energy_Downstream/Energy_Downstream.xls')\n",
    "engdwn.sheet_names\n",
    "df019= contech.parse('Sheet1')\n",
    "df20= contech.parse('Sheet2')\n",
    "\n",
    "df019.loc[df019['Capability Area'].isnull() & df019['Capability'].isnull() & df019['Process'].isnull() & df019['Sub Process'].isnull() & df019['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df019.loc[df019['Capability'].isnull() & df019['Process'].isnull() & df019['Sub Process'].isnull() & df019['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df019.loc[df019['Process'].isnull() & df019['Sub Process'].isnull() & df019['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df019.loc[df019['Sub Process'].isnull() & df019['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df019.loc[df019['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df019['Platform'] = df019['Platform'].ffill().astype(str)\n",
    "df019['Capability Area'] = df019['Capability Area'].ffill().astype(str)\n",
    "df019['Capability'] = df019['Capability'].ffill().astype(str)\n",
    "df019['Process'] = df019['Process'].ffill().astype(str)\n",
    "df019['Sub Process'] = df019['Sub Process'].ffill().astype(str)\n",
    "df019['Activity'] = df019['Activity'].ffill().astype(str)\n",
    "\n",
    "df19 = df019.replace(\"Y\", np.nan)\n",
    "\n",
    "EnrgyDwn = pd.merge(df19, df20, on = 'Asset ID', how= 'inner')\n",
    "EnrgyDwn[\"Industry\"]=\"\"\n",
    "EnrgyDwn[\"HierarId\"]=\"\"\n",
    "EnrgyDwn[\"Content\"]=\"\"\n",
    "\n",
    "#EnrgyDwn.head()\n",
    "\n",
    "\n",
    "#Creating database for EnergyUpstream\n",
    "engup = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/Energy_Upstream/Energy_Upstream.xls')\n",
    "\n",
    "\n",
    "engup.sheet_names\n",
    "df021= engup.parse('Sheet1')\n",
    "df22= engup.parse('Sheet2')\n",
    "\n",
    "df021.loc[df021['Capability Area'].isnull() & df021['Capability'].isnull() & df021['Process'].isnull() & df021['Sub Process'].isnull() & df021['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df021.loc[df021['Capability'].isnull() & df021['Process'].isnull() & df021['Sub Process'].isnull() & df021['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df021.loc[df021['Process'].isnull() & df021['Sub Process'].isnull() & df021['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df021.loc[df021['Sub Process'].isnull() & df021['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df021.loc[df021['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df021['Platform'] = df021['Platform'].ffill().astype(str)\n",
    "df021['Capability Area'] = df021['Capability Area'].ffill().astype(str)\n",
    "df021['Capability'] = df021['Capability'].ffill().astype(str)\n",
    "df021['Process'] = df021['Process'].ffill().astype(str)\n",
    "df021['Sub Process'] = df021['Sub Process'].ffill().astype(str)\n",
    "df021['Activity'] = df021['Activity'].ffill().astype(str)\n",
    "\n",
    "df21 = df021.replace(\"Y\", np.nan)\n",
    "\n",
    "EnrgyUp = pd.merge(df21, df22, on = 'Asset ID', how= 'inner')\n",
    "EnrgyUp[\"Industry\"]=\"\"\n",
    "EnrgyUp[\"HierarId\"]=\"\"\n",
    "EnrgyUp[\"Content\"]=\"\"\n",
    "\n",
    "#EnrgyUp.head()\n",
    "\n",
    "\n",
    "#Creating database for Industrial Equipment\n",
    "ineq = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/Industrial Equipment/Industrial Equipment.xls')\n",
    "\n",
    "\n",
    "ineq.sheet_names\n",
    "df023= engup.parse('Sheet1')\n",
    "df24= engup.parse('Sheet2')\n",
    "\n",
    "df023.loc[df021['Capability Area'].isnull() & df023['Capability'].isnull() & df023['Process'].isnull() & df023['Sub Process'].isnull() & df023['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df023.loc[df021['Capability'].isnull() & df023['Process'].isnull() & df023['Sub Process'].isnull() & df023['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df023.loc[df021['Process'].isnull() & df023['Sub Process'].isnull() & df023['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df023.loc[df021['Sub Process'].isnull() & df023['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df023.loc[df021['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df023['Platform'] = df023['Platform'].ffill().astype(str)\n",
    "df023['Capability Area'] = df023['Capability Area'].ffill().astype(str)\n",
    "df023['Capability'] = df023['Capability'].ffill().astype(str)\n",
    "df023['Process'] = df023['Process'].ffill().astype(str)\n",
    "df023['Sub Process'] = df023['Sub Process'].ffill().astype(str)\n",
    "df023['Activity'] = df023['Activity'].ffill().astype(str)\n",
    "\n",
    "df23 = df023.replace(\"Y\", np.nan)\n",
    "\n",
    "InduEq = pd.merge(df23, df24, on = 'Asset ID', how= 'inner')\n",
    "InduEq[\"Industry\"]=\"\"\n",
    "InduEq[\"HierarId\"]=\"\"\n",
    "InduEq[\"Content\"]=\"\"\n",
    "\n",
    "#InduEq.head()\n",
    "\n",
    "#Creating database for LifeSciences\n",
    "Lfsc = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/Life_Sciences/Life_Sciences.xls')\n",
    "\n",
    "\n",
    "Lfsc.sheet_names\n",
    "df025= Lfsc.parse('Sheet1')\n",
    "df26= Lfsc.parse('Sheet2')\n",
    "\n",
    "df025.loc[df025['Capability Area'].isnull() & df025['Capability'].isnull() & df025['Process'].isnull() & df025['Sub Process'].isnull() & df025['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df025.loc[df025['Capability'].isnull() & df025['Process'].isnull() & df025['Sub Process'].isnull() & df025['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df025.loc[df025['Process'].isnull() & df025['Sub Process'].isnull() & df025['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df025.loc[df025['Sub Process'].isnull() & df025['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df025.loc[df025['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df025['Platform'] = df025['Platform'].ffill().astype(str)\n",
    "df025['Capability Area'] = df025['Capability Area'].ffill().astype(str)\n",
    "df025['Capability'] = df025['Capability'].ffill().astype(str)\n",
    "df025['Process'] = df025['Process'].ffill().astype(str)\n",
    "df025['Sub Process'] = df025['Sub Process'].ffill().astype(str)\n",
    "df025['Activity'] = df025['Activity'].ffill().astype(str)\n",
    "\n",
    "df25 = df025.replace(\"Y\", np.nan)\n",
    "\n",
    "LifeSciences = pd.merge(df25, df26, on = 'Asset ID', how= 'inner')\n",
    "LifeSciences[\"Industry\"]=\"\"\n",
    "LifeSciences[\"HierarId\"]=\"\"\n",
    "LifeSciences[\"Content\"]=\"\"\n",
    "#LifeSciences.head()\n",
    "\n",
    "\n",
    "#Creating database for MedicalTechnology\n",
    "medt = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/Medical_Technology/Medical_Technology.xls')\n",
    "                    \n",
    "medt.sheet_names\n",
    "df027= medt.parse('Sheet1')\n",
    "df28= medt.parse('Sheet2')\n",
    "\n",
    "df027.loc[df027['Capability Area'].isnull() & df027['Capability'].isnull() & df027['Process'].isnull() & df027['Sub Process'].isnull() & df027['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df027.loc[df027['Capability'].isnull() & df027['Process'].isnull() & df027['Sub Process'].isnull() & df027['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df027.loc[df027['Process'].isnull() & df027['Sub Process'].isnull() & df027['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df027.loc[df027['Sub Process'].isnull() & df027['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df027.loc[df027['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df027['Platform'] = df027['Platform'].ffill().astype(str)\n",
    "df027['Capability Area'] = df027['Capability Area'].ffill().astype(str)\n",
    "df027['Capability'] = df027['Capability'].ffill().astype(str)\n",
    "df027['Process'] = df027['Process'].ffill().astype(str)\n",
    "df027['Sub Process'] = df027['Sub Process'].ffill().astype(str)\n",
    "df027['Activity'] = df027['Activity'].ffill().astype(str)\n",
    "\n",
    "df27 = df027.replace(\"Y\", np.nan)\n",
    "\n",
    "MedicalTechnology = pd.merge(df27, df28, on = 'Asset ID', how= 'inner')\n",
    "MedicalTechnology[\"Industry\"]=\"\"\n",
    "MedicalTechnology[\"HierarId\"]=\"\"\n",
    "MedicalTechnology[\"Content\"]=\"\"\n",
    "#MedicalTechnology.head()\n",
    "\n",
    "\n",
    "#Creating database for Metals\n",
    "met = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/Metals/Metals.xls')\n",
    "                    \n",
    "met.sheet_names\n",
    "df029= met.parse('Sheet1')\n",
    "df30= met.parse('Sheet2')\n",
    "\n",
    "df029.loc[df029['Capability Area'].isnull() & df029['Capability'].isnull() & df029['Process'].isnull() & df029['Sub Process'].isnull() & df029['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df029.loc[df029['Capability'].isnull() & df029['Process'].isnull() & df029['Sub Process'].isnull() & df029['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df029.loc[df029['Process'].isnull() &   df029['Sub Process'].isnull() & df029['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df029.loc[df029['Sub Process'].isnull() & df029['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df029.loc[df029['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df029['Platform'] = df029['Platform'].ffill().astype(str)\n",
    "df029['Capability Area'] = df029['Capability Area'].ffill().astype(str)\n",
    "df029['Capability'] = df029['Capability'].ffill().astype(str)\n",
    "df029['Process'] = df029['Process'].ffill().astype(str)\n",
    "df029['Sub Process'] = df029['Sub Process'].ffill().astype(str)\n",
    "df029['Activity'] = df029['Activity'].ffill().astype(str)\n",
    "\n",
    "df29 = df029.replace(\"Y\", np.nan)\n",
    "\n",
    "Metals = pd.merge(df29, df30, on = 'Asset ID', how= 'inner')\n",
    "Metals[\"Industry\"]=\"\"\n",
    "Metals[\"HierarId\"]=\"\"\n",
    "Metals[\"Content\"]=\"\"\n",
    "#Metals.head()\n",
    "\n",
    "#Creating database for Utilities\n",
    "utili = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/Utilities/Utilities.xls')\n",
    "                    \n",
    "utili.sheet_names\n",
    "df031= utili.parse('Sheet1')\n",
    "df32= utili.parse('Sheet2')\n",
    "\n",
    "df031.loc[df031['Capability Area'].isnull() & df031['Capability'].isnull() & df031['Process'].isnull() & df031['Sub Process'].isnull() & df031['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df031.loc[df031['Capability'].isnull() & df031['Process'].isnull() & df031['Sub Process'].isnull() & df031['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df031.loc[df031['Process'].isnull() &   df031['Sub Process'].isnull() & df031['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df031.loc[df031['Sub Process'].isnull() & df031['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df031.loc[df031['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df031['Platform'] = df031['Platform'].ffill().astype(str)\n",
    "df031['Capability Area'] = df031['Capability Area'].ffill().astype(str)\n",
    "df031['Capability'] = df031['Capability'].ffill().astype(str)\n",
    "df031['Process'] = df031['Process'].ffill().astype(str)\n",
    "df031['Sub Process'] = df031['Sub Process'].ffill().astype(str)\n",
    "df031['Activity'] = df031['Activity'].ffill().astype(str)\n",
    "\n",
    "df31 = df031.replace(\"Y\", np.nan)\n",
    "\n",
    "Utilities = pd.merge(df31, df32, on = 'Asset ID', how= 'inner')\n",
    "Utilities[\"Industry\"]=\"\"\n",
    "Utilities[\"HierarId\"]=\"\"\n",
    "Utilities[\"Content\"]=\"\"\n",
    "\n",
    "#Utilities.head()\n",
    "\n",
    "#Creating database for AESGPS\n",
    "aesgps = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/AESGPS/AESGPS.xls')\n",
    "aesgps.sheet_names\n",
    "df033= aesgps.parse('Sheet1')\n",
    "df34= aesgps.parse('Sheet2')\n",
    "\n",
    "df033.loc[df033['Capability Area'].isnull() & df033['Capability'].isnull() & df033['Process'].isnull() & df033['Sub Process'].isnull() & df033['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df033.loc[df033['Capability'].isnull() & df033['Process'].isnull() & df033['Sub Process'].isnull() & df033['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df033.loc[df033['Process'].isnull() &   df033['Sub Process'].isnull() & df033['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df033.loc[df033['Sub Process'].isnull() & df033['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df033.loc[df033['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df033['Platform'] = df033['Platform'].ffill().astype(str)\n",
    "df033['Capability Area'] = df033['Capability Area'].ffill().astype(str)\n",
    "df033['Capability'] = df033['Capability'].ffill().astype(str)\n",
    "df033['Process'] = df033['Process'].ffill().astype(str)\n",
    "df033['Sub Process'] = df033['Sub Process'].ffill().astype(str)\n",
    "df033['Activity'] = df033['Activity'].ffill().astype(str)\n",
    "\n",
    "df33 = df033.replace(\"Y\", np.nan)\n",
    "\n",
    "AESGPS = pd.merge(df33, df34, on = 'Asset ID', how= 'inner')\n",
    "AESGPS[\"Industry\"]=\"\"\n",
    "AESGPS[\"HierarId\"]=\"\"\n",
    "AESGPS[\"Content\"]=\"\"\n",
    "\n",
    "#AESGPS.head()\n",
    "\n",
    "\n",
    "#Creating database for AgriBusinessGrain\n",
    "agri = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/AgriBusinessGrain/AgriBusiness_Grain.xls')\n",
    "agri.sheet_names\n",
    "df035= agri.parse('Sheet1')\n",
    "df36= agri.parse('Sheet2')\n",
    "\n",
    "df035.loc[df035['Capability Area'].isnull() & df035['Capability'].isnull() & df035['Process'].isnull() & df035['Sub Process'].isnull() & df035['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df035.loc[df035['Capability'].isnull() & df035['Process'].isnull() & df035['Sub Process'].isnull() & df035['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df035.loc[df035['Process'].isnull() &   df035['Sub Process'].isnull() & df035['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df035.loc[df035['Sub Process'].isnull() & df035['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df035.loc[df035['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df035['Platform'] = df035['Platform'].ffill().astype(str)\n",
    "df035['Capability Area'] = df035['Capability Area'].ffill().astype(str)\n",
    "df035['Capability'] = df035['Capability'].ffill().astype(str)\n",
    "df035['Process'] = df035['Process'].ffill().astype(str)\n",
    "df035['Sub Process'] = df035['Sub Process'].ffill().astype(str)\n",
    "df035['Activity'] = df035['Activity'].ffill().astype(str)\n",
    "\n",
    "df35 = df035.replace(\"Y\", np.nan)\n",
    "\n",
    "GRAIN = pd.merge(df35, df36, on = 'Asset ID', how= 'inner')\n",
    "GRAIN[\"Industry\"]=\"\"\n",
    "GRAIN[\"HierarId\"]=\"\"\n",
    "GRAIN[\"Content\"]=\"\"\n",
    "\n",
    "#GRAIN.head()\n",
    "\n",
    "#Creating database for AIEPUtilitiesRetail\n",
    "retail = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/AIEPUtilitiesRetail/AIEPUtilitiesRetail.xls')\n",
    "retail.sheet_names\n",
    "df037= retail.parse('Sheet1')\n",
    "df38= retail.parse('Sheet2')\n",
    "\n",
    "df037.loc[df037['Capability Area'].isnull() & df037['Capability'].isnull() & df037['Process'].isnull() & df037['Sub Process'].isnull() & df037['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df037.loc[df037['Capability'].isnull() & df037['Process'].isnull() & df037['Sub Process'].isnull() & df037['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df037.loc[df037['Process'].isnull() &   df037['Sub Process'].isnull() & df037['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df037.loc[df037['Sub Process'].isnull() & df037['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df037.loc[df037['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df037['Platform'] = df037['Platform'].ffill().astype(str)\n",
    "df037['Capability Area'] = df037['Capability Area'].ffill().astype(str)\n",
    "df037['Capability'] = df037['Capability'].ffill().astype(str)\n",
    "df037['Process'] = df037['Process'].ffill().astype(str)\n",
    "df037['Sub Process'] = df037['Sub Process'].ffill().astype(str)\n",
    "df037['Activity'] = df037['Activity'].ffill().astype(str)\n",
    "\n",
    "df37 = df037.replace(\"Y\", np.nan)\n",
    "\n",
    "UTIRETAIL = pd.merge(df37, df38, on = 'Asset ID', how= 'inner')\n",
    "UTIRETAIL[\"Industry\"]=\"\"\n",
    "UTIRETAIL[\"HierarId\"]=\"\"\n",
    "UTIRETAIL[\"Content\"]=\"\"\n",
    "\n",
    "#UTIRETAIL.head()\n",
    "\n",
    "#Creating database for EnergyDownstreamMC\n",
    "engdwnmc = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/EnergyDownstreamMC/EnergyDownstreamMC.xls')\n",
    "engdwnmc.sheet_names\n",
    "df039= engdwnmc.parse('Sheet1')\n",
    "df40= engdwnmc.parse('Sheet2')\n",
    "\n",
    "df039.loc[df039['Capability Area'].isnull() & df039['Capability'].isnull() & df039['Process'].isnull() & df039['Sub Process'].isnull() & df039['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df039.loc[df039['Capability'].isnull() & df039['Process'].isnull() & df039['Sub Process'].isnull() & df039['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df039.loc[df039['Process'].isnull() &   df039['Sub Process'].isnull() & df039['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df039.loc[df039['Sub Process'].isnull() & df039['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df039.loc[df039['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df039['Platform'] = df039['Platform'].ffill().astype(str)\n",
    "df039['Capability Area'] = df039['Capability Area'].ffill().astype(str)\n",
    "df039['Capability'] = df039['Capability'].ffill().astype(str)\n",
    "df039['Process'] = df039['Process'].ffill().astype(str)\n",
    "df039['Sub Process'] = df039['Sub Process'].ffill().astype(str)\n",
    "df039['Activity'] = df039['Activity'].ffill().astype(str)\n",
    "\n",
    "df39 = df039.replace(\"Y\", np.nan)\n",
    "\n",
    "EnrgyDwnMC = pd.merge(df39, df40, on = 'Asset ID', how= 'inner')\n",
    "EnrgyDwnMC[\"Industry\"]=\"\"\n",
    "EnrgyDwnMC[\"HierarId\"]=\"\"\n",
    "EnrgyDwnMC[\"Content\"]=\"\"\n",
    "\n",
    "#EnrgyDwnMC.head()\n",
    "\n",
    "\n",
    "#Creating database for EnergyUpstreamMC\n",
    "engupmc = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/EnergyUpstreamMC/EnergyUpstreamMC.xls')\n",
    "engupmc.sheet_names\n",
    "df041= engupmc.parse('Sheet1')\n",
    "df42= engupmc.parse('Sheet2')\n",
    "\n",
    "df041.loc[df041['Capability Area'].isnull() & df041['Capability'].isnull() & df041['Process'].isnull() & df041['Sub Process'].isnull() & df041['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df041.loc[df041['Capability'].isnull() & df041['Process'].isnull() & df041['Sub Process'].isnull() & df041['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df041.loc[df041['Process'].isnull() &   df041['Sub Process'].isnull() & df041['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df041.loc[df041['Sub Process'].isnull() & df041['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df041.loc[df041['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df041['Platform'] = df041['Platform'].ffill().astype(str)\n",
    "df041['Capability Area'] = df041['Capability Area'].ffill().astype(str)\n",
    "df041['Capability'] = df041['Capability'].ffill().astype(str)\n",
    "df041['Process'] = df041['Process'].ffill().astype(str)\n",
    "df041['Sub Process'] = df041['Sub Process'].ffill().astype(str)\n",
    "df041['Activity'] = df041['Activity'].ffill().astype(str)\n",
    "\n",
    "df41 = df041.replace(\"Y\", np.nan)\n",
    "\n",
    "EnrgyUpMC = pd.merge(df41, df42, on = 'Asset ID', how= 'inner')\n",
    "EnrgyUpMC[\"Industry\"]=\"\"\n",
    "EnrgyUpMC[\"HierarId\"]=\"\"\n",
    "EnrgyUpMC[\"Content\"]=\"\"\n",
    "\n",
    "#EnrgyUpMC.head()\n",
    "\n",
    "\n",
    "#Creating database for FinanceOracle\n",
    "finorcl = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/FinanceOracle/FinanceOracle.xls')\n",
    "finorcl.sheet_names\n",
    "df043= finorcl.parse('Sheet1')\n",
    "df44= finorcl.parse('Sheet2')\n",
    "\n",
    "df043.loc[df043['Capability Area'].isnull() & df043['Capability'].isnull() & df043['Process'].isnull() & df043['Sub Process'].isnull() & df043['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df043.loc[df043['Capability'].isnull() & df043['Process'].isnull() & df043['Sub Process'].isnull() & df043['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df043.loc[df043['Process'].isnull() &   df043['Sub Process'].isnull() & df043['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df043.loc[df043['Sub Process'].isnull() & df043['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df043.loc[df043['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df043['Platform'] = df043['Platform'].ffill().astype(str)\n",
    "df043['Capability Area'] = df043['Capability Area'].ffill().astype(str)\n",
    "df043['Capability'] = df043['Capability'].ffill().astype(str)\n",
    "df043['Process'] = df043['Process'].ffill().astype(str)\n",
    "df043['Sub Process'] = df043['Sub Process'].ffill().astype(str)\n",
    "df043['Activity'] = df043['Activity'].ffill().astype(str)\n",
    "\n",
    "df43 = df043.replace(\"Y\", np.nan)\n",
    "\n",
    "FinanceOracle = pd.merge(df43, df44, on = 'Asset ID', how= 'inner')\n",
    "FinanceOracle[\"Industry\"]=\"\"\n",
    "FinanceOracle[\"HierarId\"]=\"\"\n",
    "FinanceOracle[\"Content\"]=\"\"\n",
    "\n",
    "#FinanceOracle.head()\n",
    "\n",
    "#Creating database for FinanceSAP\n",
    "finsap = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/FinanceSAP/FinanceSAP.xls')\n",
    "finsap.sheet_names\n",
    "df045= finsap.parse('Sheet1')\n",
    "df46= finsap.parse('Sheet2')\n",
    "\n",
    "df045.loc[df045['Capability Area'].isnull() & df045['Capability'].isnull() & df045['Process'].isnull() & df045['Sub Process'].isnull() & df045['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df045.loc[df045['Capability'].isnull() & df045['Process'].isnull() & df045['Sub Process'].isnull() & df045['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df045.loc[df045['Process'].isnull() &   df045['Sub Process'].isnull() & df045['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df045.loc[df045['Sub Process'].isnull() & df045['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df045.loc[df045['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df045['Platform'] = df045['Platform'].ffill().astype(str)\n",
    "df045['Capability Area'] = df045['Capability Area'].ffill().astype(str)\n",
    "df045['Capability'] = df045['Capability'].ffill().astype(str)\n",
    "df045['Process'] = df045['Process'].ffill().astype(str)\n",
    "df045['Sub Process'] = df045['Sub Process'].ffill().astype(str)\n",
    "df045['Activity'] = df045['Activity'].ffill().astype(str)\n",
    "\n",
    "df45 = df045.replace(\"Y\", np.nan)\n",
    "\n",
    "FinanceSAP = pd.merge(df45, df46, on = 'Asset ID', how= 'inner')\n",
    "FinanceSAP[\"Industry\"]=\"\"\n",
    "FinanceSAP[\"HierarId\"]=\"\"\n",
    "FinanceSAP[\"Content\"]=\"\"\n",
    "\n",
    "#FinanceSAP.head()\n",
    "\n",
    "#Creating database for Mining\n",
    "ming = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/Mining/Mining.xls')\n",
    "ming.sheet_names\n",
    "df047= ming.parse('Sheet1')\n",
    "df48= ming.parse('Sheet2')\n",
    "\n",
    "df047.loc[df047['Capability Area'].isnull() & df047['Capability'].isnull() & df047['Process'].isnull() & df047['Sub Process'].isnull() & df047['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df047.loc[df047['Capability'].isnull() & df047['Process'].isnull() & df047['Sub Process'].isnull() & df047['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df047.loc[df047['Process'].isnull() &   df047['Sub Process'].isnull() & df047['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df047.loc[df047['Sub Process'].isnull() & df047['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df047.loc[df047['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df047['Platform'] = df047['Platform'].ffill().astype(str)\n",
    "df047['Capability Area'] = df047['Capability Area'].ffill().astype(str)\n",
    "df047['Capability'] = df047['Capability'].ffill().astype(str)\n",
    "df047['Process'] = df047['Process'].ffill().astype(str)\n",
    "df047['Sub Process'] = df047['Sub Process'].ffill().astype(str)\n",
    "df047['Activity'] = df047['Activity'].ffill().astype(str)\n",
    "\n",
    "df47 = df047.replace(\"Y\", np.nan)\n",
    "\n",
    "Mining = pd.merge(df47, df48, on = 'Asset ID', how= 'inner')\n",
    "Mining[\"Industry\"]=\"\"\n",
    "Mining[\"HierarId\"]=\"\"\n",
    "Mining[\"Content\"]=\"\"\n",
    "\n",
    "#Mining.head()\n",
    "\n",
    "#Creating database for SalesCustExp\n",
    "salescus = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/SalesCustExp/SalesCustExp.xls')\n",
    "salescus.sheet_names\n",
    "df049= salescus.parse('Sheet1')\n",
    "df50= salescus.parse('Sheet2')\n",
    "\n",
    "df049.loc[df049['Capability Area'].isnull() & df049['Capability'].isnull() & df049['Process'].isnull() & df049['Sub Process'].isnull() & df049['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df049.loc[df049['Capability'].isnull() & df049['Process'].isnull() & df049['Sub Process'].isnull() & df049['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df049.loc[df049['Process'].isnull() &  df049['Sub Process'].isnull() & df049['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df049.loc[df049['Sub Process'].isnull() & df049['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df049.loc[df049['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df049['Platform'] = df049['Platform'].ffill().astype(str)\n",
    "df049['Capability Area'] = df049['Capability Area'].ffill().astype(str)\n",
    "df049['Capability'] = df049['Capability'].ffill().astype(str)\n",
    "df049['Process'] = df049['Process'].ffill().astype(str)\n",
    "df049['Sub Process'] = df049['Sub Process'].ffill().astype(str)\n",
    "df049['Activity'] = df049['Activity'].ffill().astype(str)\n",
    "\n",
    "df49 = df049.replace(\"Y\", np.nan)\n",
    "\n",
    "SalesCustExp = pd.merge(df49, df50, on = 'Asset ID', how= 'inner')\n",
    "SalesCustExp[\"Industry\"]=\"\"\n",
    "SalesCustExp[\"HierarId\"]=\"\"\n",
    "SalesCustExp[\"Content\"]=\"\"\n",
    "\n",
    "#SalesCustExp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating database for SAP_Retail\n",
    "sapr = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/SAP_Retail/SAP_Retail.xls')\n",
    "sapr.sheet_names\n",
    "df051= sapr.parse('Sheet1')\n",
    "df52= sapr.parse('Sheet2')\n",
    "\n",
    "df051.loc[df051['Capability Area'].isnull() & df051['Capability'].isnull() & df051['Process'].isnull() & df051['Sub Process'].isnull() & df051['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df051.loc[df051['Capability'].isnull() & df051['Process'].isnull() & df051['Sub Process'].isnull() & df051['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df051.loc[df051['Process'].isnull() &  df051['Sub Process'].isnull() & df051['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df051.loc[df051['Sub Process'].isnull() & df051['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df051.loc[df051['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df051['Platform'] = df051['Platform'].ffill().astype(str)\n",
    "df051['Capability Area'] = df051['Capability Area'].ffill().astype(str)\n",
    "df051['Capability'] = df051['Capability'].ffill().astype(str)\n",
    "df051['Process'] = df051['Process'].ffill().astype(str)\n",
    "df051['Sub Process'] = df051['Sub Process'].ffill().astype(str)\n",
    "df051['Activity'] = df051['Activity'].ffill().astype(str)\n",
    "\n",
    "df51 = df051.replace(\"Y\", np.nan)\n",
    "\n",
    "SAPRetail = pd.merge(df51, df52, on = 'Asset ID', how= 'inner')\n",
    "SAPRetail[\"Industry\"]=\"\"\n",
    "SAPRetail[\"HierarId\"]=\"\"\n",
    "SAPRetail[\"Content\"]=\"\"\n",
    "\n",
    "#SAPRetail.head()\n",
    "\n",
    "\n",
    "#Creating database for Travel_Airlines\n",
    "travlair = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/Travel_Airlines/Travel_Airlines.xls')\n",
    "travlair.sheet_names\n",
    "df053= travlair.parse('Sheet1')\n",
    "df54= travlair.parse('Sheet2')\n",
    "\n",
    "df053.loc[df053['Capability Area'].isnull() & df053['Capability'].isnull() & df053['Process'].isnull() & df053['Sub Process'].isnull() & df053['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df053.loc[df053['Capability'].isnull() & df053['Process'].isnull() & df053['Sub Process'].isnull() & df053['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df053.loc[df053['Process'].isnull() &  df053['Sub Process'].isnull() & df053['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df053.loc[df053['Sub Process'].isnull() & df053['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df053.loc[df053['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df053['Platform'] = df053['Platform'].ffill().astype(str)\n",
    "df053['Capability Area'] = df053['Capability Area'].ffill().astype(str)\n",
    "df053['Capability'] = df053['Capability'].ffill().astype(str)\n",
    "df053['Process'] = df053['Process'].ffill().astype(str)\n",
    "df053['Sub Process'] = df053['Sub Process'].ffill().astype(str)\n",
    "df053['Activity'] = df053['Activity'].ffill().astype(str)\n",
    "\n",
    "df53 = df053.replace(\"Y\", np.nan)\n",
    "\n",
    "TravelAirlines = pd.merge(df53, df54, on = 'Asset ID', how= 'inner')\n",
    "TravelAirlines[\"Industry\"]=\"\"\n",
    "TravelAirlines[\"HierarId\"]=\"\"\n",
    "TravelAirlines[\"Content\"]=\"\"\n",
    "\n",
    "#TravelAirlines.head()\n",
    "\n",
    "#Creating database for EnterpriseSolution\n",
    "entersol = pd.ExcelFile('C:/Users/debapriya.mukherjee/Documents/pywrk/DocumentClassification/Enterprise_Solution/Enterprise_Solution.xls')\n",
    "entersol.sheet_names\n",
    "df055= entersol.parse('Sheet1')\n",
    "df56= entersol.parse('Sheet2')\n",
    "\n",
    "df055.loc[df055['Capability Area'].isnull() & df055['Capability'].isnull() & df055['Process'].isnull() & df055['Sub Process'].isnull() & df055['Activity'].isnull(), 'Capability Area'] = \"Y\"\n",
    "df055.loc[df055['Capability'].isnull() & df055['Process'].isnull() & df055['Sub Process'].isnull() & df055['Activity'].isnull(), 'Capability'] = \"Y\"\n",
    "df055.loc[df055['Process'].isnull() &  df055['Sub Process'].isnull() & df055['Activity'].isnull(), 'Process'] = \"Y\"\n",
    "df055.loc[df055['Sub Process'].isnull() & df055['Activity'].isnull(), 'Sub Process'] = \"Y\"\n",
    "df055.loc[df055['Activity'].isnull(), 'Activity'] = \"Y\"\n",
    "\n",
    "df055['Platform'] = df055['Platform'].ffill().astype(str)\n",
    "df055['Capability Area'] = df055['Capability Area'].ffill().astype(str)\n",
    "df055['Capability'] = df055['Capability'].ffill().astype(str)\n",
    "df055['Process'] = df055['Process'].ffill().astype(str)\n",
    "df055['Sub Process'] = df055['Sub Process'].ffill().astype(str)\n",
    "df055['Activity'] = df055['Activity'].ffill().astype(str)\n",
    "\n",
    "df55 = df055.replace(\"Y\", np.nan)\n",
    "\n",
    "EnterpriseSolution = pd.merge(df55, df56, on = 'Asset ID', how= 'inner')\n",
    "EnterpriseSolution[\"Industry\"]=\"\"\n",
    "EnterpriseSolution[\"HierarId\"]=\"\"\n",
    "EnterpriseSolution[\"Content\"]=\"\"\n",
    "\n",
    "#EnterpriseSolution.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserting values to Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Inserting values to Automotive Industry\n",
    "Automotive[\"Industry\"]=\"Automotive\"\n",
    "Automotive[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in Automotive.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    Automotive.loc[i,\"HierarId\"]='AU'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "Automotive[\"Content\"] = docs\n",
    "#Automotive.head()\n",
    "\n",
    "\n",
    "###Inserting values to Chemicals Industry\n",
    "Chemicals[\"Industry\"]=\"Chemicals\"\n",
    "Chemicals[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in Chemicals.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    Chemicals.loc[i,\"HierarId\"]='CH'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "Chemicals[\"Content\"] = docs\n",
    "#Chemicals.head()\n",
    "\n",
    "\n",
    "###Inserting values to AerospaceDefense Industry\n",
    "AerospaceD[\"Industry\"]=\"AerospaceD\"\n",
    "AerospaceD[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in AerospaceD.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    AerospaceD.loc[i,\"HierarId\"]='AD'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "AerospaceD[\"Content\"] = docs\n",
    "#AerospaceD.head()\n",
    "\n",
    "\n",
    "\n",
    "###Inserting values to AgriBusinessGrain Industry\n",
    "AgriGrain[\"Industry\"]=\"AgriGrain\"\n",
    "AgriGrain[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in AgriGrain.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    AgriGrain.loc[i,\"HierarId\"]='AG'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "AgriGrain[\"Content\"] = docs\n",
    "#AgriGrain.head()\n",
    "\n",
    "\n",
    "###Inserting values to CGSNonAlcoholicBevg Industry\n",
    "NonAlcoBvg[\"Industry\"]=\"NonAlcoBvg\"\n",
    "NonAlcoBvg[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in NonAlcoBvg.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    NonAlcoBvg.loc[i,\"HierarId\"]='NB'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "NonAlcoBvg[\"Content\"] = docs\n",
    "#NonAlcoBvg.head()\n",
    "\n",
    "\n",
    "###Inserting values to CGSTobacco Industry\n",
    "Tobacco[\"Industry\"]=\"Tobacco\"\n",
    "Tobacco[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in Tobacco.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    Tobacco.loc[i,\"HierarId\"]='TB'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "Tobacco[\"Content\"] = docs\n",
    "#Tobacco.head()\n",
    "\n",
    "\n",
    "###Inserting values to ConstructionEPC\n",
    "ConstructionEPC[\"Industry\"]=\"ConstructionEPC\"\n",
    "ConstructionEPC[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in ConstructionEPC.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    ConstructionEPC.loc[i,\"HierarId\"]='EPC'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "ConstructionEPC[\"Content\"] = docs\n",
    "#ConstructionEPC.head()\n",
    "\n",
    "\n",
    "###Inserting values to ConsumerTech\n",
    "ConsumerTech[\"Industry\"]=\"ConsumerTech\"\n",
    "ConsumerTech[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in ConsumerTech.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    ConsumerTech.loc[i,\"HierarId\"]='CT'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "ConsumerTech[\"Content\"] = docs\n",
    "#ConsumerTech.head()\n",
    "\n",
    "\n",
    "###Inserting values to Defense\n",
    "Defense[\"Industry\"]=\"Defense\"\n",
    "Defense[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in Defense.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    Defense.loc[i,\"HierarId\"]='DF'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "Defense[\"Content\"] = docs\n",
    "#Defense.head()\n",
    "\n",
    "###Inserting values to EnergyDownstream\n",
    "EnrgyDwn[\"Industry\"]=\"EnergyDownstream\"\n",
    "EnrgyDwn[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in EnrgyDwn.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    EnrgyDwn.loc[i,\"HierarId\"]='ED'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "EnrgyDwn[\"Content\"] = docs\n",
    "#EnrgyDwn.head()\n",
    "\n",
    "\n",
    "###Inserting values to EnergyUpstream\n",
    "EnrgyUp[\"Industry\"]=\"EnergyUpstream\"\n",
    "EnrgyUp[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in EnrgyUp.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    EnrgyUp.loc[i,\"HierarId\"]='EU'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "EnrgyUp[\"Content\"] = docs\n",
    "#EnrgyUp.head()\n",
    "\n",
    "\n",
    "###Inserting values to Industrial Equipment\n",
    "InduEq[\"Industry\"]=\"IndustrialEquipment\"\n",
    "InduEq[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in InduEq.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    InduEq.loc[i,\"HierarId\"]='INEQ'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "InduEq[\"Content\"] = docs\n",
    "#InduEq.head()\n",
    "\n",
    "###Inserting values to LifeSciences\n",
    "LifeSciences[\"Industry\"]=\"LifeSciences\"\n",
    "LifeSciences[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in LifeSciences.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    LifeSciences.loc[i,\"HierarId\"]='LSC'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "LifeSciences[\"Content\"] = docs\n",
    "#LifeSciences.head()\n",
    "\n",
    "\n",
    "###Inserting values to MedicalTechnology\n",
    "MedicalTechnology[\"Industry\"]=\"MedicalTechnology\"\n",
    "MedicalTechnology[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in MedicalTechnology.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    MedicalTechnology.loc[i,\"HierarId\"]='MEDT'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "MedicalTechnology[\"Content\"] = docs\n",
    "#MedicalTechnology.head()\n",
    "\n",
    "###Inserting values to Metals\n",
    "Metals[\"Industry\"]=\"Metals\"\n",
    "Metals[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in Metals.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    Metals.loc[i,\"HierarId\"]='MET'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "Metals[\"Content\"] = docs\n",
    "#Metals.head()\n",
    "\n",
    "\n",
    "###Inserting values to Utilities\n",
    "Utilities[\"Industry\"]=\"Utilities\"\n",
    "Utilities[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in Utilities.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    Utilities.loc[i,\"HierarId\"]='UTIL'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "Utilities[\"Content\"] = docs\n",
    "#Utilities.head()\n",
    "\n",
    "###Inserting values to AESGPS\n",
    "AESGPS[\"Industry\"]=\"AESGPS\"\n",
    "AESGPS[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in AESGPS.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    AESGPS.loc[i,\"HierarId\"]='AES'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "AESGPS[\"Content\"] = docs\n",
    "#AESGPS.head()\n",
    "\n",
    "###Inserting values to GRAIN\n",
    "GRAIN[\"Industry\"]=\"GRAIN\"\n",
    "GRAIN[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in GRAIN.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    GRAIN.loc[i,\"HierarId\"]='GRA'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "GRAIN[\"Content\"] = docs\n",
    "#GRAIN.head()\n",
    "\n",
    "###Inserting values to AIEPUtilitiesRetail\n",
    "UTIRETAIL[\"Industry\"]=\"UtilitiesRetail\"\n",
    "UTIRETAIL[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in UTIRETAIL.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    UTIRETAIL.loc[i,\"HierarId\"]='UTR'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "UTIRETAIL[\"Content\"] = docs\n",
    "#UTIRETAIL.head()\n",
    "\n",
    "###Inserting values to EnergyDownstreamMC\n",
    "EnrgyDwnMC[\"Industry\"]=\"EnergyDownstreamMC\"\n",
    "EnrgyDwnMC[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in EnrgyDwnMC.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    EnrgyDwnMC.loc[i,\"HierarId\"]='EDMC'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "EnrgyDwnMC[\"Content\"] = docs\n",
    "#EnrgyDwnMC.head()\n",
    "\n",
    "###Inserting values to EnergyUpstreamMC\n",
    "EnrgyUpMC[\"Industry\"]=\"EnergyUpstreamMC\"\n",
    "EnrgyUpMC[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in EnrgyUpMC.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    EnrgyUpMC.loc[i,\"HierarId\"]='EUMC'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "EnrgyUpMC[\"Content\"] = docs\n",
    "#EnrgyUpMC.head()\n",
    "\n",
    "###Inserting values to FinanceOracle\n",
    "FinanceOracle[\"Industry\"]=\"FinanceOracle\"\n",
    "FinanceOracle[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in FinanceOracle.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    FinanceOracle.loc[i,\"HierarId\"]='FINORA'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "FinanceOracle[\"Content\"] = docs\n",
    "#FinanceOracle.head()\n",
    "\n",
    "###Inserting values to FinanceSAP\n",
    "FinanceSAP[\"Industry\"]=\"FinanceSAP\"\n",
    "FinanceSAP[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in FinanceSAP.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    FinanceSAP.loc[i,\"HierarId\"]='FINSAP'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "FinanceSAP[\"Content\"] = docs\n",
    "#FinanceSAP.head()\n",
    "\n",
    "###Inserting values to Mining\n",
    "Mining[\"Industry\"]=\"Mining\"\n",
    "Mining[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in Mining.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    Mining.loc[i,\"HierarId\"]='MIN'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "Mining[\"Content\"] = docs\n",
    "#Mining.head()\n",
    "\n",
    "###Inserting values to SalesCustExp\n",
    "SalesCustExp[\"Industry\"]=\"SalesCustExp\"\n",
    "SalesCustExp[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in SalesCustExp.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    SalesCustExp.loc[i,\"HierarId\"]='SCEx'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "SalesCustExp[\"Content\"] = docs\n",
    "#SalesCustExp.head()\n",
    "\n",
    "###Inserting values to SAP_Retail\n",
    "SAPRetail[\"Industry\"]=\"SAPRetail\"\n",
    "SAPRetail[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in SAPRetail.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    SAPRetail.loc[i,\"HierarId\"]='SAPR'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "SAPRetail[\"Content\"] = docs\n",
    "#SAPRetail.head()\n",
    "\n",
    "###Inserting values to Travel_Airlines\n",
    "TravelAirlines[\"Industry\"]=\"TravelAirlines\"\n",
    "TravelAirlines[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in TravelAirlines.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    TravelAirlines.loc[i,\"HierarId\"]='TRVA'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "TravelAirlines[\"Content\"] = docs\n",
    "#TravelAirlines.head()\n",
    "\n",
    "\n",
    "###Inserting values to EnterpriseSolution\n",
    "EnterpriseSolution[\"Industry\"]=\"EnterpriseSolution\"\n",
    "EnterpriseSolution[\"HierarId\"]=\"\"\n",
    "#Creating document content using url path\n",
    "docs = []\n",
    "i=0\n",
    "for link in EnterpriseSolution.iterrows():\n",
    "    url = link[1]['DrivePath']\n",
    "    text = docx2txt.process(url)\n",
    "    docs.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "    str1=link[1]['Node Name']\n",
    "    a=re.findall('\\d*\\.?\\d+',str1)\n",
    "    EnterpriseSolution.loc[i,\"HierarId\"]='ETP'+''.join(map(str,a) )\n",
    "    i+=1\n",
    "    \n",
    "EnterpriseSolution[\"Content\"] = docs\n",
    "#EnterpriseSolution.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Working Table with Industry and Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Automotive_Ind_Con=Automotive[[\"Industry\", \"Content\"]]\n",
    "Chemicals_Ind_Con=Chemicals[[\"Industry\", \"Content\"]]\n",
    "AerospaceD_Ind_Con=AerospaceD[[\"Industry\", \"Content\"]]\n",
    "AgriGrain_Ind_Con=AgriGrain[[\"Industry\", \"Content\"]]\n",
    "NonAlcoBvg_Ind_Con=NonAlcoBvg[[\"Industry\", \"Content\"]]\n",
    "Tobacco_Ind_Con=Tobacco[[\"Industry\", \"Content\"]]\n",
    "ConstructionEPC_Ind_Con=ConstructionEPC[[\"Industry\", \"Content\"]]\n",
    "ConsumerTech_Ind_Con=ConsumerTech[[\"Industry\", \"Content\"]]\n",
    "Defense_Ind_Con=Defense[[\"Industry\", \"Content\"]]\n",
    "EnrgyDwn_Ind_Con=EnrgyDwn[[\"Industry\", \"Content\"]]\n",
    "EnrgyUp_Ind_Con=EnrgyUp[[\"Industry\", \"Content\"]]\n",
    "InduEq_Ind_Con=InduEq[[\"Industry\", \"Content\"]]\n",
    "LifeSciences_Ind_Con=LifeSciences[[\"Industry\", \"Content\"]]\n",
    "MedicalTechnology_Ind_Con=MedicalTechnology[[\"Industry\", \"Content\"]]\n",
    "Metals_Ind_Con=Metals[[\"Industry\", \"Content\"]]\n",
    "Utilities_Ind_Con=Utilities[[\"Industry\", \"Content\"]]\n",
    "AESGPS_Ind_Con=AESGPS[[\"Industry\", \"Content\"]]\n",
    "Grain_Ind_Con=GRAIN[[\"Industry\", \"Content\"]]\n",
    "UTIRETAIL_Ind_Con=UTIRETAIL[[\"Industry\", \"Content\"]]\n",
    "EnrgyDwnMC_Ind_Con=EnrgyDwnMC[[\"Industry\", \"Content\"]]\n",
    "EnrgyUpMC_Ind_Con=EnrgyUpMC[[\"Industry\", \"Content\"]]\n",
    "FinanceOracle_Ind_Con=FinanceOracle[[\"Industry\", \"Content\"]]\n",
    "FinanceSAP_Ind_Con=FinanceSAP[[\"Industry\", \"Content\"]]\n",
    "Mining_Ind_Con=Mining[[\"Industry\", \"Content\"]]\n",
    "SalesCustExp_Ind_Con=SalesCustExp[[\"Industry\", \"Content\"]]\n",
    "SAPRetail_Ind_Con=SAPRetail[[\"Industry\", \"Content\"]]\n",
    "TravelAirlines_Ind_Con=TravelAirlines[[\"Industry\", \"Content\"]]\n",
    "EnterpriseSolution_Ind_Con=EnterpriseSolution[[\"Industry\", \"Content\"]]\n",
    "\n",
    "Industry_Content=Automotive_Ind_Con.append([Chemicals_Ind_Con, AerospaceD_Ind_Con, AgriGrain_Ind_Con, \n",
    "                                            NonAlcoBvg_Ind_Con, Tobacco_Ind_Con, ConstructionEPC_Ind_Con, \n",
    "                                            ConsumerTech_Ind_Con, Defense_Ind_Con, EnrgyDwn_Ind_Con, \n",
    "                                            EnrgyUp_Ind_Con, InduEq_Ind_Con, LifeSciences_Ind_Con, MedicalTechnology_Ind_Con,\n",
    "                                            Metals_Ind_Con,Utilities_Ind_Con,AESGPS_Ind_Con,Grain_Ind_Con,\n",
    "                                            UTIRETAIL_Ind_Con,EnrgyDwnMC_Ind_Con,\n",
    "                                            EnrgyUpMC_Ind_Con,FinanceOracle_Ind_Con,FinanceSAP_Ind_Con,\n",
    "                                            Mining_Ind_Con,SalesCustExp_Ind_Con,SAPRetail_Ind_Con,\n",
    "                                            TravelAirlines_Ind_Con,EnterpriseSolution_Ind_Con])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating target for model performance for 1st ML phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_topic = ['Automotive','Chemicals','AerospaceD','AgriGrain', 'NonAlcoBvg', 'Tobacco', 'ConstructionEPC',\n",
    "            'ConsumerTech','Defense', 'EnergyDownstream', 'EnergyUpstream', 'IndustrialEquipment','LifeSciences',\n",
    "           'MedicalTechnology','Metals', 'Utilities', 'AESGPS', 'AgriBusinessGrain','AIEPUtilitiesRetail',\n",
    "            'EnergyDownstreamMC','EnergyUpstreamMC','FinanceOracle','FinanceSAP','Mining','SalesCustExp',\n",
    "           'SAPRetail','TravelAirlines','EnterpriseSolution']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning vectorization and TF-IDF of the document corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=1)\n",
    "X = vectorizer.fit_transform(Industry_Content.Content)\n",
    "self_vectorizer = vectorizer\n",
    "y = Industry_Content.Industry\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the training-test split of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building up Models to train data, check accuracy and select the best performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_industry_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y_test)\n",
    "    if model_name_accuracy>final_industry_accuracy:\n",
    "        final_industry_model=model_iter\n",
    "        final_industry_accuracy=model_name_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4805755395683453\n"
     ]
    }
   ],
   "source": [
    "print('accuracy %s' % np.mean(y_pred == y_test))\n",
    "#print(classification_report(y_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Best Model for Industry Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_industry_model' (LinearSVC)\n"
     ]
    }
   ],
   "source": [
    "#Storing the Model\n",
    "get_ipython().magic('store final_industry_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_industry_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Working Table with Hierarchy and Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Automotive_Hier_Con=Automotive[[\"HierarId\", \"Content\"]]\n",
    "Chemicals_Hier_Con=Chemicals[[\"HierarId\", \"Content\"]]\n",
    "AerospaceD_Hier_Con=AerospaceD[[\"HierarId\", \"Content\"]]\n",
    "AgriGrain_Hier_Con=AgriGrain[[\"HierarId\", \"Content\"]]\n",
    "NonAlcoBvg_Hier_Con=NonAlcoBvg[[\"HierarId\", \"Content\"]]\n",
    "Tobacco_Hier_Con=Tobacco[[\"HierarId\", \"Content\"]]\n",
    "ConstructionEPC_Hier_Con=ConstructionEPC[[\"HierarId\", \"Content\"]]\n",
    "ConsumerTech_Hier_Con=ConsumerTech[[\"HierarId\", \"Content\"]]\n",
    "Defense_Hier_Con=Defense[[\"HierarId\", \"Content\"]]\n",
    "EnrgyDwn_Hier_Con=EnrgyDwn[[\"HierarId\", \"Content\"]]\n",
    "EnrgyUp_Hier_Con=EnrgyUp[[\"HierarId\", \"Content\"]]\n",
    "InduEq_Hier_Con=InduEq[[\"HierarId\", \"Content\"]]\n",
    "LifeSciences_Hier_Con=LifeSciences[[\"HierarId\", \"Content\"]]\n",
    "MedicalTechnology_Hier_Con=MedicalTechnology[[\"HierarId\", \"Content\"]]\n",
    "Metals_Hier_Con=Metals[[\"HierarId\", \"Content\"]]\n",
    "Utilities_Hier_Con=Utilities[[\"HierarId\", \"Content\"]]\n",
    "AESGPS_Hier_Con=AESGPS[[\"HierarId\", \"Content\"]]\n",
    "Grain_Hier_Con=GRAIN[[\"HierarId\", \"Content\"]]\n",
    "UTIRETAIL_Hier_Con=UTIRETAIL[[\"HierarId\", \"Content\"]]\n",
    "EnrgyDwnMC_Hier_Con=EnrgyDwnMC[[\"HierarId\", \"Content\"]]\n",
    "EnrgyUpMC_Hier_Con=EnrgyUpMC[[\"HierarId\", \"Content\"]]\n",
    "FinanceOracle_Hier_Con=FinanceOracle[[\"HierarId\", \"Content\"]]\n",
    "FinanceSAP_Hier_Con=FinanceSAP[[\"HierarId\", \"Content\"]]\n",
    "Mining_Hier_Con=Mining[[\"HierarId\", \"Content\"]]\n",
    "SalesCustExp_Hier_Con=SalesCustExp[[\"HierarId\", \"Content\"]]\n",
    "SAPRetail_Hier_Con=SAPRetail[[\"HierarId\", \"Content\"]]\n",
    "TravelAirlines_Hier_Con=TravelAirlines[[\"HierarId\", \"Content\"]]\n",
    "EnterpriseSolution_Hier_Con=EnterpriseSolution[[\"HierarId\", \"Content\"]]\n",
    "\n",
    "#Hierarchy_Content=Automotive_Hier_Con.append([Chemicals_Hier_Con, AerospaceDefense_Hier_Con, AgriGrain_Hier_Con, NonAlcoBvg_Hier_Con, Tobacco_Hier_Con, ConstructionEPC_Hier_Con])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning vectorization and TF-IDF of the document corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "vectorizer1 = TfidfVectorizer(min_df=1)\n",
    "X1 = vectorizer1.fit_transform(Chemicals_Hier_Con.Content)\n",
    "self_vectorizer_1 = vectorizer1\n",
    "y1 = Chemicals_Hier_Con.HierarId\n",
    "\n",
    "vectorizer2 = TfidfVectorizer(min_df=1)\n",
    "X2 = vectorizer2.fit_transform(Automotive_Hier_Con.Content)\n",
    "self_vectorizer_2 = vectorizer2\n",
    "y2 = Automotive_Hier_Con.HierarId\n",
    "\n",
    "vectorizer3 = TfidfVectorizer(min_df=1)\n",
    "X3 = vectorizer3.fit_transform(AerospaceD_Hier_Con.Content)\n",
    "self_vectorizer_3 = vectorizer3\n",
    "y3 = AerospaceD_Hier_Con.HierarId\n",
    "\n",
    "vectorizer4 = TfidfVectorizer(min_df=1)\n",
    "X4 = vectorizer4.fit_transform(AgriGrain_Hier_Con.Content)\n",
    "self_vectorizer_4 = vectorizer4\n",
    "y4 = AgriGrain_Hier_Con.HierarId\n",
    "\n",
    "vectorizer5 = TfidfVectorizer(min_df=1)\n",
    "X5 = vectorizer5.fit_transform(NonAlcoBvg_Hier_Con.Content)\n",
    "self_vectorizer_5 = vectorizer5\n",
    "y5 = NonAlcoBvg_Hier_Con.HierarId\n",
    "\n",
    "vectorizer6 = TfidfVectorizer(min_df=1)\n",
    "X6 = vectorizer6.fit_transform(Tobacco_Hier_Con.Content)\n",
    "self_vectorizer_6 = vectorizer6\n",
    "y6 = Tobacco_Hier_Con.HierarId\n",
    "\n",
    "vectorizer7 = TfidfVectorizer(min_df=1)\n",
    "X7 = vectorizer7.fit_transform(ConstructionEPC_Hier_Con.Content)\n",
    "self_vectorizer_7 = vectorizer7\n",
    "y7 = ConstructionEPC_Hier_Con.HierarId\n",
    "\n",
    "vectorizer8 = TfidfVectorizer(min_df=1)\n",
    "X8 = vectorizer8.fit_transform(ConsumerTech_Hier_Con.Content)\n",
    "self_vectorizer_8 = vectorizer8\n",
    "y8 = ConsumerTech_Hier_Con.HierarId\n",
    "\n",
    "\n",
    "vectorizer9 = TfidfVectorizer(min_df=1)\n",
    "X9 = vectorizer9.fit_transform(Defense_Hier_Con.Content)\n",
    "self_vectorizer_9 = vectorizer9\n",
    "y9 = Defense_Hier_Con.HierarId\n",
    "\n",
    "vectorizer10 = TfidfVectorizer(min_df=1)\n",
    "X10 = vectorizer10.fit_transform(EnrgyDwn_Hier_Con.Content)\n",
    "self_vectorizer_10 = vectorizer10\n",
    "y10 = EnrgyDwn_Hier_Con.HierarId\n",
    "\n",
    "vectorizer11 = TfidfVectorizer(min_df=1)\n",
    "X11 = vectorizer11.fit_transform(EnrgyUp_Hier_Con.Content)\n",
    "self_vectorizer_11 = vectorizer11\n",
    "y11 = EnrgyUp_Hier_Con.HierarId\n",
    "\n",
    "vectorizer12 = TfidfVectorizer(min_df=1)\n",
    "X12 = vectorizer12.fit_transform(InduEq_Hier_Con.Content)\n",
    "self_vectorizer_12 = vectorizer12\n",
    "y12= InduEq_Hier_Con.HierarId\n",
    "\n",
    "vectorizer13 = TfidfVectorizer(min_df=1)\n",
    "X13 = vectorizer13.fit_transform(LifeSciences_Hier_Con.Content)\n",
    "self_vectorizer_13 = vectorizer13\n",
    "y13= LifeSciences_Hier_Con.HierarId\n",
    "\n",
    "vectorizer14 = TfidfVectorizer(min_df=1)\n",
    "X14 = vectorizer14.fit_transform(MedicalTechnology_Hier_Con.Content)\n",
    "self_vectorizer_14 = vectorizer14\n",
    "y14 = MedicalTechnology_Hier_Con.HierarId\n",
    "\n",
    "vectorizer15 = TfidfVectorizer(min_df=1)\n",
    "X15 = vectorizer15.fit_transform(Metals_Hier_Con.Content)\n",
    "self_vectorizer_15 = vectorizer15\n",
    "y15 = Metals_Hier_Con.HierarId\n",
    "\n",
    "vectorizer16 = TfidfVectorizer(min_df=1)\n",
    "X16 = vectorizer16.fit_transform(Utilities_Hier_Con.Content)\n",
    "self_vectorizer_16 = vectorizer16\n",
    "y16 = Utilities_Hier_Con.HierarId\n",
    "\n",
    "vectorizer17 = TfidfVectorizer(min_df=1)\n",
    "X17 = vectorizer17.fit_transform(AESGPS_Hier_Con.Content)\n",
    "self_vectorizer_17 = vectorizer17\n",
    "y17 = AESGPS_Hier_Con.HierarId\n",
    "\n",
    "vectorizer18 = TfidfVectorizer(min_df=1)\n",
    "X18 = vectorizer18.fit_transform(Grain_Hier_Con.Content)\n",
    "self_vectorizer_18 = vectorizer18\n",
    "y18 = Grain_Hier_Con.HierarId\n",
    "\n",
    "vectorizer19 = TfidfVectorizer(min_df=1)\n",
    "X19 = vectorizer19.fit_transform(UTIRETAIL_Hier_Con.Content)\n",
    "self_vectorizer_19 = vectorizer19\n",
    "y19 = UTIRETAIL_Hier_Con.HierarId\n",
    "\n",
    "vectorizer20 = TfidfVectorizer(min_df=1)\n",
    "X20 = vectorizer20.fit_transform(EnrgyDwnMC_Hier_Con.Content)\n",
    "self_vectorizer_20 = vectorizer20\n",
    "y20 = EnrgyDwnMC_Hier_Con.HierarId\n",
    "\n",
    "vectorizer21 = TfidfVectorizer(min_df=1)\n",
    "X21 = vectorizer21.fit_transform(EnrgyUpMC_Hier_Con.Content)\n",
    "self_vectorizer_21 = vectorizer21\n",
    "y21 = EnrgyUpMC_Hier_Con.HierarId\n",
    "\n",
    "vectorizer22 = TfidfVectorizer(min_df=1)\n",
    "X22 = vectorizer22.fit_transform(FinanceOracle_Hier_Con.Content)\n",
    "self_vectorizer_22 = vectorizer22\n",
    "y22 = FinanceOracle_Hier_Con.HierarId\n",
    "\n",
    "vectorizer23 = TfidfVectorizer(min_df=1)\n",
    "X23 = vectorizer23.fit_transform(FinanceSAP_Hier_Con.Content)\n",
    "self_vectorizer_23 = vectorizer23\n",
    "y23 = FinanceSAP_Hier_Con.HierarId\n",
    "\n",
    "vectorizer24 = TfidfVectorizer(min_df=1)\n",
    "X24 = vectorizer24.fit_transform(Mining_Hier_Con.Content)\n",
    "self_vectorizer_24 = vectorizer24\n",
    "y24 = Mining_Hier_Con.HierarId\n",
    "\n",
    "vectorizer25 = TfidfVectorizer(min_df=1)\n",
    "X25 = vectorizer25.fit_transform(SalesCustExp_Hier_Con.Content)\n",
    "self_vectorizer_25 = vectorizer25\n",
    "y25 = SalesCustExp_Hier_Con.HierarId\n",
    "\n",
    "vectorizer26 = TfidfVectorizer(min_df=1)\n",
    "X26 = vectorizer26.fit_transform(SAPRetail_Hier_Con.Content)\n",
    "self_vectorizer_26 = vectorizer26\n",
    "y26 = SAPRetail_Hier_Con.HierarId\n",
    "\n",
    "vectorizer27 = TfidfVectorizer(min_df=1)\n",
    "X27 = vectorizer27.fit_transform(TravelAirlines_Hier_Con.Content)\n",
    "self_vectorizer_27 = vectorizer27\n",
    "y27 = TravelAirlines_Hier_Con.HierarId\n",
    "\n",
    "vectorizer28 = TfidfVectorizer(min_df=1)\n",
    "X28 = vectorizer28.fit_transform(EnterpriseSolution_Hier_Con.Content)\n",
    "self_vectorizer_28 = vectorizer28\n",
    "y28 = EnterpriseSolution_Hier_Con.HierarId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the training-test split of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.3, random_state=0)\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.3, random_state=0)\n",
    "\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.3, random_state=0)\n",
    "\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, test_size=0.3, random_state=0)\n",
    "\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(X5, y5, test_size=0.3, random_state=0)\n",
    "\n",
    "X6_train, X6_test, y6_train, y6_test = train_test_split(X6, y6, test_size=0.3, random_state=0)\n",
    "\n",
    "X7_train, X7_test, y7_train, y7_test = train_test_split(X7, y7, test_size=0.3, random_state=0)\n",
    "\n",
    "X8_train, X8_test, y8_train, y8_test = train_test_split(X8, y8, test_size=0.3, random_state=0)\n",
    "\n",
    "X9_train, X9_test, y9_train, y9_test = train_test_split(X9, y9, test_size=0.3, random_state=0)\n",
    "\n",
    "X10_train, X10_test, y10_train, y10_test = train_test_split(X10, y10, test_size=0.3, random_state=0)\n",
    "\n",
    "X11_train, X11_test, y11_train, y11_test = train_test_split(X11, y11, test_size=0.3, random_state=0)\n",
    "\n",
    "X12_train, X12_test, y12_train, y12_test = train_test_split(X12, y12, test_size=0.3)\n",
    "\n",
    "X13_train, X13_test, y13_train, y13_test = train_test_split(X13, y13, test_size=0.3, random_state=0)\n",
    "\n",
    "X14_train, X14_test, y14_train, y14_test = train_test_split(X14, y14, test_size=0.3, random_state=0)\n",
    "\n",
    "X15_train, X15_test, y15_train, y15_test = train_test_split(X15, y15, test_size=0.3, random_state=0)\n",
    "\n",
    "X16_train, X16_test, y16_train, y16_test = train_test_split(X16, y16, test_size=0.3, random_state=0)\n",
    "\n",
    "X17_train, X17_test, y17_train, y17_test = train_test_split(X17, y17, test_size=0.3, random_state=0)\n",
    "\n",
    "X18_train, X18_test, y18_train, y18_test = train_test_split(X18, y18, test_size=0.3, random_state=0)\n",
    "\n",
    "X19_train, X19_test, y19_train, y19_test = train_test_split(X19, y19, test_size=0.3, random_state=0)\n",
    "\n",
    "X20_train, X20_test, y20_train, y20_test = train_test_split(X20, y20, test_size=0.3, random_state=0)\n",
    "\n",
    "X21_train, X21_test, y21_train, y21_test = train_test_split(X21, y21, test_size=0.3, random_state=0)\n",
    "\n",
    "X22_train, X22_test, y22_train, y22_test = train_test_split(X22, y22, test_size=0.3, random_state=0)\n",
    "\n",
    "X23_train, X23_test, y23_train, y23_test = train_test_split(X23, y23, test_size=0.3, random_state=0)\n",
    "\n",
    "X24_train, X24_test, y24_train, y24_test = train_test_split(X24, y24, test_size=0.3, random_state=0)\n",
    "\n",
    "X25_train, X25_test, y25_train, y25_test = train_test_split(X25, y25, test_size=0.3, random_state=0)\n",
    "\n",
    "X26_train, X26_test, y26_train, y26_test = train_test_split(X26, y26, test_size=0.3, random_state=0)\n",
    "\n",
    "X27_train, X27_test, y27_train, y27_test = train_test_split(X27, y27, test_size=0.3, random_state=0)\n",
    "\n",
    "X28_train, X28_test, y28_train, y28_test = train_test_split(X28, y28, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building industry specific Hierarchy Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_Chemicals_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.43333333333333335\n"
     ]
    }
   ],
   "source": [
    "##Chemicals Hierarchy\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_chemicals_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X1_train, y1_train)\n",
    "    y_pred = model.predict(X1_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y1_test)\n",
    "    if model_name_accuracy>final_chemicals_accuracy:\n",
    "        final_Chemicals_model=model_iter\n",
    "        final_chemicals_accuracy=model_name_accuracy\n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_Chemicals_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_Chemicals_model')\n",
    "\n",
    "\n",
    "print(final_Chemicals_model)\n",
    "print(final_chemicals_accuracy)\n",
    "#print(classification_report(y1_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_Automotive_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "##Automotive Hierarchy\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_automotive_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X2_train, y2_train)\n",
    "    y_pred = model.predict(X2_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y2_test)\n",
    "    if model_name_accuracy>final_automotive_accuracy:\n",
    "        final_Automotive_model=model_iter\n",
    "        final_automotive_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_Automotive_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_Automotive_model')\n",
    "\n",
    "print(final_Automotive_model)\n",
    "print(final_automotive_accuracy)\n",
    "#print(classification_report(y2_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_AerospaceD_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "##AerospaceD Hierarchy\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_aerospaced_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X3_train, y3_train)\n",
    "    y_pred = model.predict(X3_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y3_test)\n",
    "    if model_name_accuracy>final_aerospaced_accuracy:\n",
    "        final_AerospaceD_model=model_iter\n",
    "        final_aerospaced_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_AerospaceD_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_AerospaceD_model')\n",
    "\n",
    "print(final_AerospaceD_model)\n",
    "print(final_aerospaced_accuracy)\n",
    "#print(classification_report(y3_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y3_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_AgriGrain_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "##AgriBusinessGrain Hierarchy\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_agrigrain_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X4_train, y4_train)\n",
    "    y_pred = model.predict(X4_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y4_test)\n",
    "    if model_name_accuracy>final_agrigrain_accuracy:\n",
    "        final_AgriGrain_model=model_iter\n",
    "        final_agrigrain_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_AgriGrain_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_AgriGrain_model')\n",
    "\n",
    "print(final_AgriGrain_model)\n",
    "print(final_agrigrain_accuracy)\n",
    "#print(classification_report(y4_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y4_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_NonAlcoBvg_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.43333333333333335\n"
     ]
    }
   ],
   "source": [
    "##CGSNonAlcoholicBevg Hierarchy\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_nonalcobvg_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X5_train, y5_train)\n",
    "    y_pred = model.predict(X5_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y5_test)\n",
    "    if model_name_accuracy>final_nonalcobvg_accuracy:\n",
    "        final_NonAlcoBvg_model=model_iter\n",
    "        final_nonalcobvg_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_NonAlcoBvg_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_NonAlcoBvg_model')\n",
    "\n",
    "\n",
    "print(final_NonAlcoBvg_model)\n",
    "print(final_nonalcobvg_accuracy)\n",
    "#print(classification_report(y5_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y5_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_Tobacco_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "##CGSTobacco Hierarchy\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_tobacco_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X6_train, y6_train)\n",
    "    y_pred = model.predict(X6_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y6_test)\n",
    "    if model_name_accuracy>final_tobacco_accuracy:\n",
    "        final_Tobacco_model=model_iter\n",
    "        final_tobacco_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_Tobacco_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_Tobacco_model')\n",
    "\n",
    "print(final_Tobacco_model)\n",
    "print(final_tobacco_accuracy)\n",
    "#print(classification_report(y6_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y6_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_ConstructionEPC_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "#ConstructionEPC Hierarchy\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_constructionepc_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X7_train, y7_train)\n",
    "    y_pred = model.predict(X7_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y7_test)\n",
    "    if model_name_accuracy>final_constructionepc_accuracy:\n",
    "        final_ConstructionEPC_model=model_iter\n",
    "        final_constructionepc_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_ConstructionEPC_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_constructionEPC_model')\n",
    "\n",
    "print(final_ConstructionEPC_model)\n",
    "print(final_constructionepc_accuracy)\n",
    "#print(classification_report(y7_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y7_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_ConsumerTech_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.3225806451612903\n"
     ]
    }
   ],
   "source": [
    "#ConsumerTech Hierarchy\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_consumertech_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X8_train, y8_train)\n",
    "    y_pred = model.predict(X8_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y8_test)\n",
    "    if model_name_accuracy>final_consumertech_accuracy:\n",
    "        final_ConsumerTech_model=model_iter\n",
    "        final_consumertech_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_ConsumerTech_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_ConsumerTech_model')\n",
    "\n",
    "print(final_ConsumerTech_model)\n",
    "print(final_consumertech_accuracy)\n",
    "#print(classification_report(y8_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y8_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_Defense_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.3225806451612903\n"
     ]
    }
   ],
   "source": [
    "#Defense Hierarchy\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_defense_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X9_train, y9_train)\n",
    "    y_pred = model.predict(X9_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y9_test)\n",
    "    if model_name_accuracy>final_defense_accuracy:\n",
    "        final_Defense_model=model_iter\n",
    "        final_defense_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_Defense_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_Defense_model')\n",
    "\n",
    "print(final_Defense_model)\n",
    "print(final_defense_accuracy)\n",
    "#print(classification_report(y9_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y9_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_EnergyDownstream_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.3225806451612903\n"
     ]
    }
   ],
   "source": [
    "#EnergyDownstream Hierarchy\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_energydownstream_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X10_train, y10_train)\n",
    "    y_pred = model.predict(X10_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y10_test)\n",
    "    if model_name_accuracy>final_energydownstream_accuracy:\n",
    "        final_EnergyDownstream_model=model_iter\n",
    "        final_energydownstream_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_EnergyDownstream_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_EnergyDownstream_model')\n",
    "\n",
    "print(final_EnergyDownstream_model)\n",
    "print(final_energydownstream_accuracy)\n",
    "#print(classification_report(y10_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y10_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_EnergyUpstream_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.43333333333333335\n"
     ]
    }
   ],
   "source": [
    "#EnergyUpstream Hierarchy\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_energyupstream_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X11_train, y11_train)\n",
    "    y_pred = model.predict(X11_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y11_test)\n",
    "    if model_name_accuracy>final_energyupstream_accuracy:\n",
    "        final_EnergyUpstream_model=model_iter\n",
    "        final_energyupstream_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_EnergyUpstream_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_EnergyUpstream_model')\n",
    "\n",
    "print(final_EnergyUpstream_model)\n",
    "print(final_energyupstream_accuracy)\n",
    "#print(classification_report(y11_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y11_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_IndustrialEquipment_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.36666666666666664\n"
     ]
    }
   ],
   "source": [
    "#IndustrialEquipment Hierarchy\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_industrialequipment_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X12_train, y12_train)\n",
    "    y_pred = model.predict(X12_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y12_test)\n",
    "    if model_name_accuracy>final_industrialequipment_accuracy:\n",
    "        final_IndustrialEquipment_model=model_iter\n",
    "        final_industrialequipment_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_IndustrialEquipment_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_IndustrialEquipment_model')\n",
    "\n",
    "print(final_IndustrialEquipment_model)\n",
    "print(final_industrialequipment_accuracy)\n",
    "#print(classification_report(y12_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y12_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_LifeSciences_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_lifesciences_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X13_train, y13_train)\n",
    "    y_pred = model.predict(X13_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y13_test)\n",
    "    if model_name_accuracy>final_lifesciences_accuracy:\n",
    "        final_LifeSciences_model=model_iter\n",
    "        final_lifesciences_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_LifeSciences_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_LifeSciences_model')\n",
    "\n",
    "print(final_LifeSciences_model)\n",
    "print(final_lifesciences_accuracy)\n",
    "#print(classification_report(y13_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y13_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_MedicalTechnology_model' (RandomForestClassifier)\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
      "0.15384615384615385\n"
     ]
    }
   ],
   "source": [
    "#Medical Technology Hierarchy\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_medicaltech_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X14_train, y14_train)\n",
    "    y_pred = model.predict(X14_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y14_test)\n",
    "    if model_name_accuracy>final_medicaltech_accuracy:\n",
    "        final_MedicalTechnology_model=model_iter\n",
    "        final_medicaltech_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_MedicalTechnology_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_MedicalTechnology_model')\n",
    "\n",
    "print(final_MedicalTechnology_model)\n",
    "print(final_medicaltech_accuracy)\n",
    "#print(classification_report(y14_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y14_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_Metals_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.27586206896551724\n"
     ]
    }
   ],
   "source": [
    "#Metals Hierarchy\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_metals_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X15_train, y15_train)\n",
    "    y_pred = model.predict(X15_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y15_test)\n",
    "    if model_name_accuracy>final_metals_accuracy:\n",
    "        final_Metals_model=model_iter\n",
    "        final_metals_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_Metals_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_Metals_model')\n",
    "\n",
    "print(final_Metals_model)\n",
    "print(final_metals_accuracy)\n",
    "#print(classification_report(y15_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y15_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_Utilities_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 5604)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Utilities Hierarchy\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_util_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X16_train, y16_train)\n",
    "    y_pred = model.predict(X16_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y16_test)\n",
    "    if model_name_accuracy>final_util_accuracy:\n",
    "        final_Utilities_model=model_iter\n",
    "        final_util_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_Utilities_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_Utilities_model')\n",
    "\n",
    "print(final_Utilities_model)\n",
    "print(final_util_accuracy)\n",
    "#print(classification_report(y16_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y16_test))\n",
    "\n",
    "X16.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_AESGPS_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.36666666666666664\n"
     ]
    }
   ],
   "source": [
    "#AESGPS Hierarchy\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_aesgps_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X17_train, y17_train)\n",
    "    y_pred = model.predict(X17_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y17_test)\n",
    "    if model_name_accuracy>final_aesgps_accuracy:\n",
    "        final_AESGPS_model=model_iter\n",
    "        final_aesgps_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_AESGPS_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_AESGPS_model')\n",
    "\n",
    "print(final_AESGPS_model)\n",
    "print(final_aesgps_accuracy)\n",
    "#print(classification_report(y17_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y17_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_AgriBusinessGrain_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "#AgriBusinessGrain Hierarchy\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_grain_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X18_train, y18_train)\n",
    "    y_pred = model.predict(X18_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y18_test)\n",
    "    if model_name_accuracy>final_grain_accuracy:\n",
    "        final_AgriBusinessGrain_model=model_iter\n",
    "        final_grain_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_AgriBusinessGrain_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_AgriBusinessGrain_model')\n",
    "\n",
    "print(final_AgriBusinessGrain_model)\n",
    "print(final_grain_accuracy)\n",
    "#print(classification_report(y18_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y18_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_AIEPUtilitiesRetail_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.06666666666666667\n"
     ]
    }
   ],
   "source": [
    "#AIEPUtilitiesRetail Hierarchy\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_aiutilre_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X19_train, y19_train)\n",
    "    y_pred = model.predict(X19_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y19_test)\n",
    "    if model_name_accuracy>final_aiutilre_accuracy:\n",
    "        final_AIEPUtilitiesRetail_model=model_iter\n",
    "        final_aiutilre_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_AIEPUtilitiesRetail_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_AIEPUtilitiesRetail_model')\n",
    "\n",
    "print(final_AIEPUtilitiesRetail_model)\n",
    "print(final_aiutilre_accuracy)\n",
    "#print(classification_report(y19_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y19_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_EnergyDownstreamMC_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "#EnrgyDwnMC Hierarchy\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_engdwnmc_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X20_train, y20_train)\n",
    "    y_pred = model.predict(X20_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y20_test)\n",
    "    if model_name_accuracy>final_engdwnmc_accuracy:\n",
    "        final_EnergyDownstreamMC_model=model_iter\n",
    "        final_engdwnmc_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_EnergyDownstreamMC_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_EnergyDownstreamMC_model')\n",
    "\n",
    "print(final_EnergyDownstreamMC_model)\n",
    "print(final_engdwnmc_accuracy)\n",
    "#print(classification_report(y20_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y20_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_EnergyUpstreamMC_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.2222222222222222\n"
     ]
    }
   ],
   "source": [
    "#EnrgyUpMC Hierarchy\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_EnrgyUpMC_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X21_train, y21_train)\n",
    "    y_pred = model.predict(X21_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y21_test)\n",
    "    if model_name_accuracy>final_EnrgyUpMC_accuracy:\n",
    "        final_EnergyUpstreamMC_model=model_iter\n",
    "        final_EnrgyUpMC_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_EnergyUpstreamMC_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_EnergyUpstreamMC_model')\n",
    "\n",
    "print(final_EnergyUpstreamMC_model)\n",
    "print(final_EnrgyUpMC_accuracy)\n",
    "#print(classification_report(y21_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y21_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_FinanceOracle_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#FinanceOracle Hierarchy\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_finorcle_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X22_train, y22_train)\n",
    "    y_pred = model.predict(X22_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y22_test)\n",
    "    if model_name_accuracy>final_finorcle_accuracy:\n",
    "        final_FinanceOracle_model=model_iter\n",
    "        final_finorcle_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_FinanceOracle_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_FinanceOracle_model')\n",
    "\n",
    "print(final_FinanceOracle_model)\n",
    "print(final_finorcle_accuracy)\n",
    "#print(classification_report(y22_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y22_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_FinanceSAP_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "#FinanceSAP Hierarchy\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_finSAP_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X23_train, y23_train)\n",
    "    y_pred = model.predict(X23_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y23_test)\n",
    "    if model_name_accuracy>final_finSAP_accuracy:\n",
    "        final_FinanceSAP_model=model_iter\n",
    "        final_finSAP_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_FinanceSAP_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_FinanceSAP_model')\n",
    "\n",
    "print(final_FinanceSAP_model)\n",
    "print(final_finSAP_accuracy)\n",
    "#print(classification_report(y23_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y23_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_Mining_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.24\n"
     ]
    }
   ],
   "source": [
    "#Mining Hierarchy\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_ming_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X24_train, y24_train)\n",
    "    y_pred = model.predict(X24_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y24_test)\n",
    "    if model_name_accuracy>final_ming_accuracy:\n",
    "        final_Mining_model=model_iter\n",
    "        final_ming_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_Mining_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_Mining_model')\n",
    "\n",
    "print(final_Mining_model)\n",
    "print(final_ming_accuracy)\n",
    "#print(classification_report(y24_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y24_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_SalesCustExp_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "##SalesCustExp Hierarchy\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_scexp_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X25_train, y25_train)\n",
    "    y_pred = model.predict(X25_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y25_test)\n",
    "    if model_name_accuracy>final_scexp_accuracy:\n",
    "        final_SalesCustExp_model=model_iter\n",
    "        final_scexp_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_SalesCustExp_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_SalesCustExp_model')\n",
    "\n",
    "print(final_SalesCustExp_model)\n",
    "print(final_scexp_accuracy)\n",
    "#print(classification_report(y25_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y25_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_SAPRetail_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.3157894736842105\n"
     ]
    }
   ],
   "source": [
    "#SAPRetail Hierarchy\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_sapret_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X26_train, y26_train)\n",
    "    y_pred = model.predict(X26_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y26_test)\n",
    "    if model_name_accuracy>final_sapret_accuracy:\n",
    "        final_SAPRetail_model=model_iter\n",
    "        final_sapret_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_SAPRetail_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_SAPRetail_model')\n",
    "\n",
    "print(final_SAPRetail_model)\n",
    "print(final_sapret_accuracy)\n",
    "#print(classification_report(y26_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y26_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_TravelAirlines_model' (LinearSVC)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "#TravelAirlines Hierarchy\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_travlair_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X27_train, y27_train)\n",
    "    y_pred = model.predict(X27_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y27_test)\n",
    "    if model_name_accuracy>final_travlair_accuracy:\n",
    "        final_TravelAirlines_model=model_iter\n",
    "        final_travlair_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_TravelAirlines_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_TravelAirlines_model')\n",
    "\n",
    "print(final_TravelAirlines_model)\n",
    "print(final_travlair_accuracy)\n",
    "#print(classification_report(y27_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y27_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'final_EnterpriseSolution_model' (RandomForestClassifier)\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
      "0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "#EnterpriseSolution Hierarchy\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "final_entsol_accuracy=0\n",
    "for model_iter in models:\n",
    "    model = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', model_iter),\n",
    "               ])\n",
    "    model.fit(X28_train, y28_train)\n",
    "    y_pred = model.predict(X28_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_name_accuracy=np.mean(y_pred == y28_test)\n",
    "    if model_name_accuracy>final_entsol_accuracy:\n",
    "        final_EnterpriseSolution_model=model_iter\n",
    "        final_entsol_accuracy=model_name_accuracy\n",
    "        \n",
    "\n",
    "#Storing the Model\n",
    "get_ipython().magic('store final_EnterpriseSolution_model')\n",
    "\n",
    "#Retrieving the stored model\n",
    "#get_ipython().magic('store -r final_EnterpriseSolution_model')\n",
    "\n",
    "print(final_EnterpriseSolution_model)\n",
    "print(final_entsol_accuracy)\n",
    "#print(classification_report(y28_test, y_pred,target_names=my_topic))\n",
    "#print(confusion_matrix(y_pred, y28_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Industry on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chemicals', 'Automotive', 'MedicalTechnology', 'Utilities'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=[\"C:\\\\Users\\\\debapriya.mukherjee\\\\Documents\\\\pywrk\\\\DocumentClassification\\\\Chemicals\\\\test data\\\\AP322_Collections Management.docx\",\n",
    "     \"C:\\\\Users\\\\debapriya.mukherjee\\\\Documents\\\\pywrk\\\\DocumentClassification\\\\Automotive\\\\Test Data\\\\AP322_SCS_AIIT_DRP Approval.docx\",\n",
    "     \"C:\\\\Users\\\\debapriya.mukherjee\\\\Documents\\\\pywrk\\\\DocumentClassification\\\\Life_Sciences\\\\test\\\\BP315_FS_PH_Accounts Payable and Payment Processing.docx\",\n",
    "     \"C:\\\\Users\\\\debapriya.mukherjee\\\\Documents\\\\pywrk\\\\DocumentClassification\\\\Utilities\\\\test\\\\BP315_Utilities_Define Profit Center Accounting Organization.docx\"\n",
    "    ]\n",
    "\n",
    "docs= Industry_Content.Content\n",
    "vectorizer = TfidfVectorizer(min_df=1)\n",
    "X_newdoc = vectorizer.fit_transform(docs)\n",
    "self_vectorizer = vectorizer\n",
    "new_input = []\n",
    "for i in range(len(url)):\n",
    "    text = docx2txt.process(url[i])\n",
    "    new_input.append(detokenizer.detokenize(word_tokenize(text), return_str=True))\n",
    "\n",
    "#self_vectorizer=Industry_Content.Content\n",
    "X_new = self_vectorizer.transform(new_input)\n",
    "industry_pred=final_industry_model.predict(X_new)\n",
    "\n",
    "                                    \n",
    "\n",
    "industry_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call hierarchy Model as per Industry output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_Chemicals_model\n",
      "final_Automotive_model\n",
      "final_MedicalTechnology_model\n",
      "final_Utilities_model\n"
     ]
    }
   ],
   "source": [
    "hierarchy_models=['final_Chemicals_model', 'final_Automotive_model','final_AerospaceD_model','final_AgriGrain_model',\n",
    "                  'final_NonAlcoBvg_model','final_Tobacco_model','final_ConstructionEPC_model',\n",
    "                  'final_ConsumerTech_model','final_Defense_model','final_EnergyDownstream_model',\n",
    "                  'final_EnergyUpstream_model','final_InduEq_model',' final_LifeSciences_model',\n",
    "                  'final_MedicalTechnology_model','final_Metals_model','final_Utilities_model','final_AESGPS_model',\n",
    "                  'final_AgriBusinessGrain_model','final_AIEPUtilitiesRetail_model','final_EnergyDownstreamMC_model',\n",
    "                  'final_EnergyUpstreamMC_model','final_FinanceOracle_model','final_FinanceSAP_model',\n",
    "                  'final_Mining_model','final_SalesCustExp_model','final_SAPRetail_model','final_TravelAirlines_model',\n",
    "                  'final_EnterpriseSolution_model']\n",
    "\n",
    "final_hierarchy_pred=[]\n",
    "for i in range(len(url)):\n",
    "    final_hierarchy_model = [ str for str in hierarchy_models if industry_pred[i] in str ] \n",
    "    print(final_hierarchy_model[0])\n",
    "    if industry_pred[i]=='Chemicals':\n",
    "        X_new_1=self_vectorizer_1.transform(new_input)\n",
    "    elif industry_pred[i]=='Automotive':\n",
    "        X_new_1=self_vectorizer_2.transform(new_input)\n",
    "    elif industry_pred[i]=='AerospaceD':\n",
    "        X_new_1=self_vectorizer_3.transform(new_input)\n",
    "    elif industry_pred[i]=='AgriGrain':\n",
    "        X_new_1=self_vectorizer_4.transform(new_input)\n",
    "    elif industry_pred[i]=='NonAlcoBvg':\n",
    "        X_new_1=self_vectorizer_5.transform(new_input)\n",
    "    elif industry_pred[i]=='Tobacco':\n",
    "        X_new_1=self_vectorizer_6.transform(new_input)\n",
    "    elif industry_pred[i]=='ConstructionEPC':\n",
    "        X_new_1=self_vectorizer_7.transform(new_input)\n",
    "    elif industry_pred[i]=='ConsumerTech':\n",
    "        X_new_1=self_vectorizer_8.transform(new_input)\n",
    "    elif industry_pred[i]=='Defense':\n",
    "        X_new_1=self_vectorizer_9.transform(new_input)\n",
    "    elif industry_pred[i]=='EnergyDownstream':\n",
    "        X_new_1=self_vectorizer_10.transform(new_input)\n",
    "    elif industry_pred[i]=='EnergyUpstream':\n",
    "        X_new_1=self_vectorizer_11.transform(new_input)\n",
    "    elif industry_pred[i]=='IndustrialEquipment':\n",
    "        X_new_1=self_vectorizer_12.transform(new_input)\n",
    "    elif industry_pred[i]=='LifeSciences':\n",
    "        X_new_1=self_vectorizer_13.transform(new_input)\n",
    "    elif industry_pred[i]=='MedicalTechnology':\n",
    "        X_new_1=self_vectorizer_14.transform(new_input)\n",
    "    elif industry_pred[i]=='Metals':\n",
    "        X_new_1=self_vectorizer_15.transform(new_input)\n",
    "    elif industry_pred[i]=='Utilities':\n",
    "        X_new_1=self_vectorizer_16.transform(new_input)\n",
    "    elif industry_pred[i]=='AESGPS':\n",
    "        X_new_1=self_vectorizer_17.transform(new_input)\n",
    "    elif industry_pred[i]=='AgriBusinessGrain':\n",
    "        X_new_1=self_vectorizer_18.transform(new_input)\n",
    "    elif industry_pred[i]=='AIEPUtilitiesRetail':\n",
    "        X_new_1=self_vectorizer_19.transform(new_input)\n",
    "    elif industry_pred[i]=='EnergyDownstreamMC':\n",
    "        X_new_1=self_vectorizer_20.transform(new_input)\n",
    "    elif industry_pred[i]=='EnergyUpstreamMC':\n",
    "        X_new_1=self_vectorizer_21.transform(new_input)\n",
    "    elif industry_pred[i]=='FinanceOracle':\n",
    "        X_new_1=self_vectorizer_22.transform(new_input)\n",
    "    elif industry_pred[i]=='FinanceSAP':\n",
    "        X_new_1=self_vectorizer_23.transform(new_input)\n",
    "    elif industry_pred[i]=='Mining':\n",
    "        X_new_1=self_vectorizer_24.transform(new_input)\n",
    "    elif industry_pred[i]=='SalesCustExp':\n",
    "        X_new_1=self_vectorizer_25.transform(new_input)\n",
    "    elif industry_pred[i]=='SAPRetail':\n",
    "        X_new_1=self_vectorizer_26.transform(new_input)\n",
    "    elif industry_pred[i]=='TravelAirlines':\n",
    "        X_new_1=self_vectorizer_27.transform(new_input)\n",
    "    elif industry_pred[i]=='EnterpriseSolution':\n",
    "        X_new_1=self_vectorizer_28.transform(new_input)\n",
    "    \n",
    "    str=\"hierarchy_pred=\"+final_hierarchy_model[0]+\".predict(X_new_1)[i]\"\n",
    "    exec(str)\n",
    "    final_hierarchy_pred.append(hierarchy_pred[0])\n",
    "\n",
    "\n",
    "#print(final_hierarchy_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call hierarchy details as per the identifier of Industry table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01 Plan and Manage Enterprise - 01.03 Plan and Manage Financial Performance - 01.03.04  Manage Corporate Finance - 01.03.04.01  Perform Banking Activities - 01.03.04.01.01 Process electronic bank statement reconciliation', '02 Sales Service and Marketing - 02.03 Customer Service Management - 02.03.02 Customer Feedback Management - 02.03.02.01 Maintain CRM Master Data - 02.03.02.01.06 Pricing Strategy Maintenance', '01 Define Business and Operating Strategy - 01.02 Develop and Align Organization Strategy - 01.02.05 Manage Change Journey - 01.02.05.02 Define Leader and User Leadership Team', '01 Plan and Manage the Enterprise - 01.01 Manage Finance Function - 01.01.01 Manage Finance Organization - 01.01.01.01 Create Finance Organization Structure - 01.01.01.01.01 Define and Maintain Financial Organization']\n"
     ]
    }
   ],
   "source": [
    "path_list=[]\n",
    "for i in range(len(url)):\n",
    "    hierarchy_str= \"hierarchy_data=\"+industry_pred[i]\n",
    "    exec(hierarchy_str)\n",
    "    hierarchy_data.index = range(len(hierarchy_data.index))\n",
    "    path=\"\"\n",
    "    if pd.isnull(hierarchy_data.loc[0,'Platform'])==False: path=hierarchy_data.loc[0,'Platform']\n",
    "    if pd.isnull(hierarchy_data.loc[0,'Capability Area'])==False: path=path+\" - \"+hierarchy_data.loc[0,'Capability Area']\n",
    "    if pd.isnull(hierarchy_data.loc[0,'Capability'])==False: path=path+\" - \"+hierarchy_data.loc[0,'Capability']\n",
    "    if pd.isnull(hierarchy_data.loc[0,'Process'])==False: path=path+\" - \"+hierarchy_data.loc[0,'Process']\n",
    "    if pd.isnull(hierarchy_data.loc[0,'Sub Process'])==False: path=path+\" - \"+hierarchy_data.loc[0,'Sub Process']\n",
    "    if pd.isnull(hierarchy_data.loc[0,'Activity'])==False: path=path+\" - \"+hierarchy_data.loc[0,'Activity']\n",
    "    path_list.append(path)\n",
    "\n",
    "print(path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
